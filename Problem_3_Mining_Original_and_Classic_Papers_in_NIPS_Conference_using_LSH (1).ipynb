{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem 3: Mining Original and Classic Papers in NIPS Conference using LSH.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x3RfNtwO3Ih",
        "outputId": "52659915-90cd-49b3-f8ed-cef5a1b89b58"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "url='https://papers.nips.cc/paper/2017'\n",
        "r=requests.get(url)\n",
        "htmlContent=r.content\n",
        "soup= BeautifulSoup(htmlContent,'lxml')\n",
        "titles=[]\n",
        "authors=[]\n",
        "papers_url=[]\n",
        "\n",
        "for i in soup('div',class_='col',)and soup.find_all('li'):\n",
        "  titles.append(i.a.text)\n",
        "  authors.append(i.i.text)\n",
        "  paper_url=\"https://papers.nips.cc/\" + i.find('a').get(\"href\")\n",
        "  papers_url.append(paper_url)\n",
        "  \n",
        "titles.remove('')\n",
        "titles.remove('')\n",
        "authors.remove('')\n",
        "authors.remove('')\n",
        "papers_url.remove(papers_url[0])\n",
        "papers_url.remove(papers_url[0])\n",
        "print(titles)\n",
        "print(authors)\n",
        "print(papers_url)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Real Time Image Saliency for Black Box Classifiers', 'Joint distribution optimal transportation for domain adaptation', 'Learning A Structured Optimal Bipartite Graph for Co-Clustering', 'Learning to Inpaint for Image Compression', 'Inverse Filtering for Hidden Markov Models', 'On clustering network-valued data', 'Langevin Dynamics with Continuous Tempering for Training Deep Neural Networks', 'Beyond Worst-case: A Probabilistic Analysis of Affine Policies in Dynamic Optimization', 'Few-Shot Learning Through an Information Retrieval  Lens', 'Accelerated consensus via Min-Sum Splitting', 'Saliency-based Sequential Image Attention with Multiset Prediction', 'Adaptive Bayesian Sampling with Monte Carlo EM', 'Scalable Levy Process Priors for Spectral Kernel Learning', 'Model-Powered Conditional Independence Test', 'Learning Multiple Tasks with Multilinear Relationship Networks', 'Query Complexity of Clustering with Side Information', 'Non-parametric Structured Output Networks', 'Robust Imitation of Diverse Behaviors', 'High-Order Attention Models for Visual Question Answering', 'FALKON: An Optimal Large Scale Kernel Method', 'Generalized Linear Model Regression under Distance-to-set Penalties', 'Fisher GAN', 'Minimax Estimation of Bandable Precision Matrices', 'Kernel functions based on triplet comparisons', 'Breaking the Nonsmooth Barrier: A Scalable Parallel Method for Composite Optimization', 'A New Theory for Matrix Completion', 'A Bayesian Data Augmentation Approach for Learning Deep Models', 'Deep Hyperalignment', 'Best of Both Worlds: Transferring Knowledge from Discriminative Learning to a Generative Visual Dialog Model', 'PASS-GLM: polynomial approximate sufficient statistics for scalable Bayesian GLM inference', 'Online multiclass boosting', 'State Aware Imitation Learning', 'Adaptive SVRG Methods under Error Bound Conditions with Unknown Growth Parameter', 'Unsupervised Learning of Disentangled and Interpretable Representations from Sequential Data', 'Recurrent Ladder Networks', 'Distral: Robust multitask reinforcement learning', 'Real-Time Bidding with Side Information', 'Learning Spherical Convolution for Fast Features from 360° Imagery', 'Approximate Supermodularity Bounds for Experimental Design', 'Differentiable Learning of Logical Rules for Knowledge Base Reasoning', 'When Cyclic Coordinate Descent Outperforms Randomized Coordinate Descent', 'Principles of Riemannian Geometry  in Neural Networks', 'Continual Learning with Deep Generative Replay', 'Nonlinear random matrix theory for deep learning', 'Identification of Gaussian Process State Space Models', 'Estimation of the covariance structure of heavy-tailed distributions', 'Robust Optimization for Non-Convex Objectives', 'Exploring Generalization in Deep Learning', 'Spherical convolutions and their application in molecular modelling', 'Safe Adaptive Importance Sampling', 'Introspective Classification with Convolutional Nets', 'Hybrid Reward Architecture for Reinforcement Learning', 'When Worlds Collide: Integrating Different Counterfactual Assumptions in Fairness', 'Dualing GANs', 'A Universal Analysis of Large-Scale Regularized Least Squares Solutions', 'Diffusion Approximations for Online Principal Component Estimation and Global Convergence', 'k-Support and Ordered Weighted Sparsity for Overlapping Groups: Hardness and Algorithms', 'Learning to Model the Tail', 'Neural Variational Inference and Learning in Undirected Graphical Models', 'Aggressive Sampling for Multi-class to Binary Reduction with Applications to Text Classification', 'Learning Linear Dynamical Systems via Spectral Filtering', 'Efficient Modeling of Latent Information in Supervised Learning using Gaussian Processes', 'Semi-Supervised Learning for Optical Flow with Generative Adversarial Networks', 'Phase Transitions in the Pooled Data Problem', 'Unifying PAC and Regret: Uniform PAC Bounds for Episodic Reinforcement Learning', 'Stein Variational Gradient Descent as Gradient Flow', 'Expectation Propagation for t-Exponential Family Using q-Algebra', 'Collaborative PAC Learning', 'Polynomial time algorithms for dual volume sampling', 'Premise Selection for Theorem Proving by Deep Graph Embedding', 'Differentiable Learning of Submodular Models', 'YASS: Yet Another Spike Sorter', 'Variational Laws of Visual Attention for Dynamic Scenes', 'How regularization affects the critical points in linear networks', 'On Tensor Train Rank Minimization : Statistical Efficiency and Scalable Algorithm', 'EX2: Exploration with Exemplar Models for Deep Reinforcement Learning', 'Training Quantized Nets: A Deeper Understanding', 'Convolutional Gaussian Processes', 'Best Response Regression', 'Elementary Symmetric Polynomials for Optimal Experimental Design', 'Learning from Complementary Labels', 'Dynamic Importance Sampling for Anytime Bounds of the Partition Function', 'Process-constrained batch Bayesian optimisation', 'Uprooting and Rerooting Higher-Order Graphical Models', 'Learned in Translation: Contextualized Word Vectors', 'Semisupervised Clustering, AND-Queries and Locally Encodable Source Coding', 'Regularizing Deep Neural Networks by Noise: Its Interpretation and Optimization', 'Few-Shot Adversarial Domain Adaptation', 'Robust and Efficient Transfer Learning with Hidden Parameter Markov Decision Processes', 'Multi-View Decision Processes: The Helper-AI Problem', 'Maximum Margin Interval Trees', 'Online Learning with a Hint', 'DPSCREEN: Dynamic Personalized Screening', 'Online Learning of Optimal Bidding Strategy in Repeated Multi-Commodity Auctions', 'A-NICE-MC: Adversarial Training for MCMC', 'Question Asking as Program Generation', 'Gradient Methods for Submodular Maximization', 'Recycling Privileged Learning and Distribution Matching for Fairness', 'Collecting Telemetry Data Privately', 'Parallel Streaming Wasserstein Barycenters', 'Adaptive Accelerated Gradient Converging Method under H\\\\\"{o}lderian Error Bound Condition', 'What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?', 'Reconstruct & Crush Network', 'Permutation-based Causal Inference Algorithms with Interventions', 'Deep Dynamic Poisson Factorization Model', 'Scalable Generalized Linear Bandits: Online Computation and Hashing', 'Experimental Design for Learning Causal Graphs with Latent Variables', 'Lower bounds on the robustness to adversarial perturbations', 'Reliable Decision Support using Counterfactual Models', 'Group Additive Structure Identification for Kernel Nonparametric Regression', 'A multi-agent reinforcement learning model of common-pool resource appropriation', 'Decoding with Value Networks for Neural Machine Translation', 'Population Matching Discrepancy and Applications in Deep Learning', 'Predictive State Recurrent Neural Networks', 'Robust Hypothesis Test for Nonlinear Effect with Gaussian Processes', 'Sharpness, Restart and Acceleration', 'Dynamic Routing Between Capsules', 'InfoGAIL: Interpretable Imitation Learning from Visual Demonstrations', 'A Regularized Framework for Sparse and Structured Neural Attention', 'Style Transfer from Non-Parallel Text by Cross-Alignment', 'Unsupervised Learning of Disentangled Representations from Video', 'Countering Feedback Delays in Multi-Agent Learning', 'Affinity Clustering: Hierarchical Clustering at Scale', 'Geometric Matrix Completion with Recurrent Multi-Graph Neural Networks', 'Maximizing Subset Accuracy with Recurrent Neural Networks in Multi-label Classification', 'f-GANs in an Information Geometric Nutshell', 'Active Bias: Training More Accurate Neural Networks by Emphasizing High Variance Samples', 'SchNet: A continuous-filter convolutional neural network for modeling quantum interactions', 'GibbsNet: Iterative Adversarial Inference for Deep Graphical Models', 'Bayesian GAN', 'Alternating minimization for dictionary learning with random initialization', 'Sparse Embedded $k$-Means Clustering', 'Reducing Reparameterization Gradient Variance', 'Min-Max Propagation', 'Statistical Cost Sharing', 'Dilated Recurrent Neural Networks', 'The Expressive Power of Neural Networks: A View from the Width', 'Inverse Reward Design', 'The power of absolute discounting: all-dimensional distribution estimation', 'A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning', 'Spectral Mixture Kernels for Multi-Output Gaussian Processes', 'Affine-Invariant Online Optimization and the Low-rank Experts Problem', 'Pose Guided Person Image Generation', 'Successor Features for Transfer in Reinforcement Learning', 'On Quadratic Convergence of DC Proximal Newton Algorithm in Nonconvex Sparse Learning', 'Hypothesis Transfer Learning via Transformation Functions', 'Finite Sample Analysis of the GTD Policy Evaluation Algorithms in Markov Setting', 'Variational Inference via $\\\\chi$ Upper Bound Minimization', 'A Probabilistic Framework for Nonlinearities in Stochastic Neural Networks', 'Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation', 'Optimistic posterior sampling for reinforcement learning: worst-case regret bounds', 'Efficient Second-Order Online Kernel Learning with Adaptive Embedding', 'Solving Most Systems of Random Quadratic Equations', 'Online Reinforcement Learning in Stochastic Games', 'Independence clustering (without a matrix)', 'Effective Parallelisation for Machine Learning', 'Deep Mean-Shift Priors for Image Restoration', 'On Structured Prediction Theory with Calibrated Convex Surrogate Losses', 'Invariance and Stability of Deep Convolutional Representations', 'Variational Memory Addressing in Generative Models', 'Shallow Updates for Deep Reinforcement Learning', 'Learning with Bandit Feedback in Potential Games', 'A Greedy Approach for Budgeted Maximum Inner Product Search', 'Riemannian approach to batch normalization', 'Adaptive Clustering through Semidefinite Programming', '#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning', 'Learning Koopman Invariant Subspaces for Dynamic Mode Decomposition', 'Online Prediction with Selfish Experts', 'Streaming Robust Submodular Maximization: A Partitioned Thresholding Approach', 'Neural Program Meta-Induction', 'The Scaling Limit of High-Dimensional Online Independent Component Analysis', 'Practical Locally Private Heavy Hitters', 'Mixture-Rank Matrix Approximation for Collaborative Filtering', 'Higher-Order Total Variation Classes on Grids: Minimax Theory and Trend Filtering Methods', 'Robust Conditional Probabilities', 'Attention is All you Need', 'A General Framework for Robust Interactive Learning', 'Sample and Computationally Efficient Learning Algorithms under S-Concave Distributions', 'Net-Trim: Convex Pruning of Deep Neural Networks with Performance Guarantee', 'ELF: An Extensive, Lightweight and Flexible Research Platform for Real-time Strategy Games', 'Task-based End-to-end Model Learning in Stochastic Optimization', 'Fader Networks:Manipulating Images by Sliding Attributes', 'VAE Learning via Stein Variational Gradient Descent', 'Approximation and Convergence Properties of Generative Adversarial Learning', 'VEEGAN: Reducing Mode Collapse in GANs using Implicit Variational Learning', 'Local Aggregative Games', 'An Error Detection and Correction Framework for Connectomics', 'Hindsight Experience Replay', 'Fixed-Rank Approximation of a Positive-Semidefinite Matrix from Streaming Data', 'The Numerics of GANs', 'Cortical microcircuits as gated-recurrent neural networks', 'Deep Lattice Networks and Partial Monotonic Functions', 'Zap Q-Learning', 'Contrastive Learning for Image Captioning', 'Variational Walkback: Learning a Transition Operator as a Stochastic Recurrent Net', 'Linear Time Computation of Moments in Sum-Product Networks', 'SGD Learns the Conjugate Kernel Class of the Network', 'Learning to Pivot with Adversarial Networks', 'Near-linear time approximation algorithms for optimal transport via Sinkhorn iteration', 'Universal Style Transfer via Feature Transforms', 'Ensemble Sampling', 'Practical Data-Dependent Metric Compression with Provable Guarantees', 'Partial Hard Thresholding: Towards A Principled Analysis of Support Recovery', 'Selective Classification for Deep Neural Networks', 'Diverse and Accurate Image Description Using a Variational Auto-Encoder with an Additive Gaussian Encoding Space', 'Deconvolutional Paragraph Representation Learning', 'Learning to See Physics via Visual De-animation', 'Adversarial Symmetric Variational Autoencoder', 'Model evidence from nonequilibrium simulations', 'Estimating High-dimensional Non-Gaussian Multiple Index Models via Stein’s Lemma', 'Learning spatiotemporal piecewise-geodesic trajectories from longitudinal manifold-valued data', 'SVD-Softmax: Fast Softmax Approximation on Large Vocabulary Neural Networks', 'Concentration of Multilinear Functions of the Ising Model with Applications to Network Data', 'Rigorous Dynamics and Consistent Estimation in Arbitrarily Conditioned Linear Systems', 'OnACID: Online Analysis of Calcium Imaging Data in Real Time', 'Action Centered Contextual Bandits', 'Cost efficient gradient boosting', 'Eigenvalue Decay Implies Polynomial-Time Learnability for Neural Networks', 'On Separability of Loss Functions, and Revisiting Discriminative Vs Generative Models', 'ExtremeWeather: A large-scale climate dataset for semi-supervised detection, localization, and understanding of extreme weather events', 'A Meta-Learning Perspective on Cold-Start Recommendations for Items', 'Learning Unknown Markov Decision Processes: A Thompson Sampling Approach', 'Deep Hyperspherical Learning', 'Interpretable and Globally Optimal Prediction for Textual Grounding using Image Concepts', 'Off-policy evaluation for slate recommendation', 'Unbiased estimates for linear regression via volume sampling', 'Revisiting Perceptron: Efficient and Label-Optimal Learning of Halfspaces', 'Renyi Differential Privacy Mechanisms for Posterior Sampling', 'Variable Importance Using Decision Trees', 'A simple model of recognition and recall memory', 'Implicit Regularization in Matrix Factorization', 'Continuous DR-submodular  Maximization: Structure and Algorithms', 'Decoupling \"when to update\" from \"how to update\"', 'Regret Analysis for Continuous Dueling Bandit', 'One-Sided Unsupervised Domain Mapping', 'Poincaré Embeddings for Learning Hierarchical Representations', 'Variance-based Regularization with Convex Objectives', 'A Sharp Error Analysis for the Fused Lasso, with Application to Approximate Changepoint Screening', 'Cross-Spectral Factor Analysis', 'Self-Normalizing Neural Networks', 'Fast amortized inference of neural activity from calcium imaging data with variational autoencoders', 'Asynchronous Parallel Coordinate Minimization for MAP Inference', 'Inductive Representation Learning on Large Graphs', 'Data-Efficient Reinforcement Learning in Continuous State-Action Gaussian-POMDPs', 'Coded Distributed Computing for Inverse Problems', \"Dykstra's Algorithm, ADMM, and Coordinate Descent: Connections, Insights, and Extensions\", 'Training recurrent networks to generate hypotheses about how the brain solves hard navigation problems', 'SafetyNets: Verifiable Execution of Deep Neural Networks on an Untrusted Cloud', 'Improved Graph Laplacian via Geometric Self-Consistency', 'Generalization Properties of Learning with Random Features', 'Predictive-State Decoders: Encoding the Future into Recurrent Networks', 'Federated Multi-Task Learning', 'Learning Causal Structures Using Regression Invariance', 'Practical Hash Functions for Similarity Estimation and Dimensionality Reduction', 'Gaussian Quadrature for Kernel Features', 'Multi-Modal Imitation Learning from Unstructured Demonstrations using Generative Adversarial Nets', 'Greedy Algorithms for Cone Constrained Optimization with Convergence Guarantees', 'On the Fine-Grained Complexity of Empirical Risk Minimization: Kernel Methods and Neural Networks', 'Acceleration and Averaging in Stochastic Descent Dynamics', 'LightGBM: A Highly Efficient Gradient Boosting Decision Tree', 'The Neural Hawkes Process: A Neurally Self-Modulating Multivariate Point Process', 'Bayesian Optimization with Gradients', 'Visual Reference Resolution using Attention Memory for Visual Dialog', 'Straggler Mitigation in Distributed Optimization Through Data Encoding', 'Using Options and Covariance Testing for Long Horizon Off-Policy Policy Evaluation', 'Attentional Pooling for Action Recognition', 'Testing and Learning on Distributions with Symmetric Noise Invariance', 'Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results', 'Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments', 'Log-normality and Skewness of Estimated State/Action Values in Reinforcement Learning', 'Bayesian Compression for Deep Learning', 'Is Input Sparsity Time Possible for Kernel Low-Rank Approximation?', 'Convergent Block Coordinate Descent for Training Tikhonov Regularized Deep Neural Networks', 'Bayesian Inference of Individualized Treatment Effects using Multi-task Gaussian Processes', 'Learning Overcomplete HMMs', 'Convolutional Phase Retrieval', 'Stochastic and Adversarial Online Learning without Hyperparameters', 'Masked Autoregressive Flow for Density Estimation', 'QSGD: Communication-Efficient SGD via Gradient Quantization and Encoding', 'Learning Hierarchical Information Flow with Recurrent Neural Modules', 'Deanonymization in the Bitcoin P2P Network', 'Learning with Average Top-k Loss', 'MaskRNN: Instance Level Video Object Segmentation', 'Max-Margin Invariant Features from Transformed Unlabelled Data', 'Sparse Approximate Conic Hulls', 'Label Distribution Learning Forests', 'Efficient Sublinear-Regret Algorithms for Online Sparse Linear Regression with Limited Observation', 'Accelerated First-order Methods for Geodesically Convex Optimization on Riemannian Manifolds', 'Hierarchical Implicit Models and Likelihood-Free Variational Inference', 'Learning the Morphology of Brain Signals Using Alpha-Stable Convolutional Sparse Coding', 'Modulating early visual processing by language', 'Discriminative State Space Models', 'Emergence of Language with Multi-agent Games: Learning to Communicate with Sequences of Symbols', 'Wider and Deeper, Cheaper and Faster: Tensorized LSTMs for Sequence Learning', 'Online Influence Maximization under Independent Cascade Model with Semi-Bandit Feedback', 'Smooth Primal-Dual Coordinate Descent Algorithms for Nonsmooth Convex Optimization', 'Linearly constrained Gaussian processes', 'Solid Harmonic Wavelet Scattering: Predicting Quantum Molecular Energy from Invariant Descriptors of 3D  Electronic Densities', 'On Frank-Wolfe and Equilibrium Computation', 'Generalizing GANs: A Turing Perspective', 'Predicting Scene Parsing and Motion Dynamics in the Future', 'A Screening Rule for l1-Regularized Ising Model Estimation', 'A Minimax Optimal Algorithm for Crowdsourcing', 'Communication-Efficient Distributed Learning of Discrete Distributions', 'VAIN: Attentional Multi-agent Predictive Modeling', 'Hierarchical Attentive Recurrent Tracking', 'Sobolev Training for Neural Networks', 'Doubly Accelerated Stochastic Variance Reduced Dual Averaging Method for Regularized Empirical Risk Minimization', 'Learning with Feature Evolvable Streams', 'Safe Model-based Reinforcement Learning with Stability Guarantees', 'Time-dependent spatially varying graphical models, with application to brain fMRI data analysis', 'Clone MCMC: Parallel High-Dimensional Gaussian Gibbs Sampling', 'Context Selection for Embedding Models', 'Union of Intersections (UoI) for Interpretable Data Driven Discovery and Prediction', 'Good Semi-supervised Learning That Requires a Bad GAN', 'Targeting EEG/LFP Synchrony with Neural Nets', 'Learning from uncertain curves: The 2-Wasserstein metric for Gaussian processes', 'Online Dynamic Programming', 'Neural Discrete Representation Learning', 'Probabilistic Rule Realization and Selection', 'A Disentangled Recognition and Nonlinear Dynamics Model for Unsupervised Learning', 'Stabilizing Training of Generative Adversarial Networks through Regularization', 'Training Deep Networks without Learning Rates Through Coin Betting', 'Dual-Agent GANs for Photorealistic and Identity Preserving Profile Face Synthesis', 'Thy Friend is My Friend: Iterative Collaborative Filtering for Sparse Matrix Estimation', 'Positive-Unlabeled Learning with Non-Negative Risk Estimator', 'Gradient descent GAN optimization is locally stable', 'Faster and Non-ergodic O(1/K) Stochastic Alternating Direction Method of Multipliers', 'Group Sparse Additive Machine', 'PixelGAN Autoencoders', 'Excess Risk Bounds for the Bayes Risk using Variational Inference in Latent Gaussian Models', 'Online control of the false discovery rate with decaying memory', 'Safe and Nested Subgame Solving for Imperfect-Information Games', 'A PAC-Bayesian Analysis of Randomized Learning with Application to Stochastic Gradient Descent', 'Dynamic Safe Interruptibility for Decentralized Multi-Agent Reinforcement Learning', 'Toward Multimodal Image-to-Image Translation', 'The Marginal Value of Adaptive Gradient Methods in Machine Learning', 'Mean Field Residual Networks: On the Edge of Chaos', 'Non-convex Finite-Sum Optimization Via SCSG Methods', 'First-Order Adaptive Sample Size Methods to Reduce Complexity of Empirical Risk Minimization', 'Doubly Stochastic Variational Inference for Deep Gaussian Processes', 'From Parity to Preference-based Notions of Fairness in Classification', 'Nonparametric Online Regression while Learning the Metric', 'Stochastic Optimization with Variance Reduction for Infinite Datasets with Finite Sum Structure', \"Working hard to know your neighbor's margins: Local descriptor learning loss\", 'Hiding Images in Plain Sight: Deep Steganography', 'Lookahead  Bayesian Optimization with Inequality Constraints', 'Online Learning with Transductive Regret', 'Pixels to Graphs by Associative Embedding', 'Accelerated Stochastic Greedy Coordinate Descent by Soft Thresholding Projection onto Simplex', 'Reinforcement Learning under Model Mismatch', 'Concrete Dropout', 'Multiresolution Kernel Approximation for Gaussian Process Regression', 'Near Minimax Optimal Players for the Finite-Time 3-Expert Prediction Problem', 'Learned D-AMP: Principled Neural Network based Compressive Image Recovery', 'Deep Multi-task Gaussian Processes for Survival Analysis with Competing Risks', 'Unsupervised Transformation Learning via Convex Relaxations', 'Soft-to-Hard Vector Quantization for End-to-End Learning Compressible Representations', 'Accuracy First: Selecting a Differential Privacy Level for Accuracy Constrained ERM', 'Triple Generative Adversarial Nets', 'Deep Learning with Topological Signatures', 'Revenue Optimization with Approximate Bid Predictions', 'Mapping distinct timescales of functional interactions among brain networks', 'Improved Training of Wasserstein GANs', 'Adaptive stimulus selection for optimizing neural population responses', 'Matrix Norm Estimation from a Few Entries', 'On the Power of Truncated SVD for General High-rank Matrix Estimation Problems', 'TernGrad: Ternary Gradients to Reduce Communication in Distributed Deep Learning', 'GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium', 'A Unified Approach to Interpreting Model Predictions', 'Nonbacktracking Bounds on the Influence in Independent Cascade Models', 'Linear Convergence of a Frank-Wolfe Type Algorithm over Trace-Norm Balls', 'Fully Decentralized Policies for Multi-Agent Systems: An Information Theoretic Approach', 'Neural system identification for large populations separating “what” and “where”', 'Learning Active Learning from Data', 'Controllable Invariance through Adversarial Feature Learning', 'Visual Interaction Networks: Learning a Physics Simulator from Video', 'Repeated Inverse Reinforcement Learning', 'Inference in Graphical Models via Semidefinite Programming Hierarchies', 'Gauging Variational Inference', 'Teaching Machines to Describe Images with Natural Language Feedback', 'Associative Embedding: End-to-End Learning for Joint Detection and Grouping', 'Information Theoretic Properties of Markov Random Fields, and their Algorithmic Applications', 'Subset Selection and Summarization in Sequential Data', 'Z-Forcing: Training Stochastic Recurrent Networks', 'Regret Minimization in MDPs with Options without Prior Knowledge', 'Learning Identifiable Gaussian Bayesian Networks in Polynomial Time and Sample Complexity', 'Learning Neural Representations of Human Cognition across Many fMRI Studies', 'Conic Scan-and-Cover algorithms for nonparametric topic modeling', 'Online Learning for Multivariate Hawkes Processes', 'An Empirical Study on The Properties of Random Bases for Kernel Methods', 'Nearest-Neighbor Sample Compression: Efficiency, Consistency, Infinite Dimensions', 'Causal Effect Inference with Deep Latent-Variable Models', 'Estimating Accuracy from Unlabeled Data: A Probabilistic Logic Approach', 'A Decomposition of Forecast Error in Prediction Markets', 'Ranking Data with Continuous Labels through Oriented Recursive Partitions', 'Scalable Log Determinants for Gaussian Process Kernel Learning', 'Fair Clustering Through Fairlets', 'A Linear-Time Kernel Goodness-of-Fit Test', 'Rotting Bandits', 'Scalable Planning with Tensorflow for Hybrid Nonlinear Domains', 'Probabilistic Models for Integration Error in the Assessment of Functional Cardiac Models', 'Bandits Dueling on Partially Ordered Sets', 'Decomposition-Invariant Conditional Gradient for General Polytopes with Line Search', 'Multiscale Semi-Markov Dynamics for Intracortical Brain-Computer Interfaces', 'Fast Black-box Variational Inference through Stochastic Trust-Region Optimization', 'Revisit Fuzzy Neural Network: Demystifying Batch Normalization and ReLU with Generalized Hamming Network', 'Optimized Pre-Processing for Discrimination Prevention', 'Scalable Demand-Aware Recommendation', 'Learning a Multi-View Stereo Machine', 'On Blackbox Backpropagation and Jacobian Sensing', 'Learning Disentangled Representations with Semi-Supervised Deep Generative Models', 'GP CaKe: Effective brain connectivity with causal kernels', 'Certified Defenses for Data Poisoning Attacks', 'Towards Generalization and Simplicity in Continuous Control', 'Imagination-Augmented Agents for Deep Reinforcement Learning', 'Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles', 'Adaptive Active Hypothesis Testing under Limited Information', 'Translation Synchronization via Truncated Least Squares', 'Limitations on Variance-Reduction and Acceleration Schemes for Finite Sums Optimization', 'Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep Neural Networks', 'Recursive Sampling for the Nystrom Method', 'Early stopping for kernel boosting algorithms: A general analysis with localized complexities', 'Interpolated Policy Gradient: Merging On-Policy and Off-Policy Gradient Estimation for Deep Reinforcement Learning', 'Parameter-Free Online Learning via Model Selection', 'Predicting User Activity Level In Point Processes With Mass Transport Equation', 'The Importance of Communities for Learning to Influence', 'Gradients of Generative Models for Improved Discriminative Analysis of Tandem Mass Spectra', 'On the Optimization Landscape of Tensor Decompositions', 'Counterfactual Fairness', 'Efficient Online Linear Optimization with Approximation Algorithms', 'Inhomogeneous Hypergraph Clustering with Applications', 'Runtime Neural Pruning', 'Train longer, generalize better: closing the generalization gap in large batch training of neural networks', 'Monte-Carlo Tree Search by Best Arm Identification', 'Deep Learning for Precipitation Nowcasting: A Benchmark and A New Model', 'Scalable Model Selection for Belief Networks', 'Collaborative Deep Learning in Fixed Topology Networks', 'On the Complexity of Learning Neural Networks', 'A Sample Complexity Measure with Applications to Learning Optimal Auctions', 'On Optimal Generalizability in Parametric Learning', 'K-Medoids For K-Means Seeding', 'Learning Deep Structured Multi-Scale Features using Attention-Gated CRFs for Contour Prediction', 'Geometric Descent Method for Convex Composite Minimization', 'Label Efficient Learning of Transferable Representations acrosss Domains and Tasks', 'Improving Regret Bounds for Combinatorial Semi-Bandits with Probabilistically Triggered Arms and Its Applications', 'Matching neural paths: transfer from recognition to correspondence search', 'Convergence Analysis of Two-layer Neural Networks with ReLU Activation', 'Quantifying how much sensory information in a neural code is relevant for behavior', 'Self-supervised Learning of Motion Capture', 'Toward Goal-Driven Neural Network Models for the Rodent Whisker-Trigeminal System', 'Clustering Billions of Reads for DNA Data Storage', 'AIDE: An algorithm for measuring the accuracy of probabilistic inference algorithms', 'Information-theoretic analysis of generalization capability of learning algorithms', 'MarrNet: 3D Shape Reconstruction via 2.5D Sketches', 'Flexible statistical inference for mechanistic models of neural dynamics', 'ALICE: Towards Understanding Adversarial Learning for Joint Distribution Matching', 'Speeding Up Latent Variable Gaussian Graphical Model Estimation via Nonconvex Optimization', 'Sparse convolutional coding for neuronal assembly detection', 'Neural Networks for Efficient Bayesian Decoding of Natural Images from Retinal Neurons', 'Plan, Attend, Generate: Planning for Sequence-to-Sequence Models', 'Analyzing Hidden Representations in End-to-End Automatic Speech Recognition Systems', 'Multi-Task Learning for Contextual Bandits', 'Temporal Coherency based Criteria for Predicting Video Frames using Deep Multi-stage Generative Adversarial Networks', 'Improving the Expected Improvement Algorithm', 'Towards Accurate Binary Convolutional Neural Network', 'Spectrally-normalized margin bounds for neural networks', 'Consistent Multitask Learning with Nonlinear Output Relations', 'Deep Recurrent Neural Network-Based Identification of Precursor microRNAs', 'Boltzmann Exploration Done Right', 'End-to-end Differentiable Proving', 'Matching on Balanced Nonlinear Representations for Treatment Effects Estimation', 'Tomography of the London Underground: a Scalable Model for Origin-Destination Data', 'Gaussian process based nonlinear latent structure discovery in multivariate spike train data', 'Multi-Objective Non-parametric Sequential Prediction', 'Optimal Sample Complexity of M-wise Data for Top-K Ranking', 'From which world is your graph', 'An Empirical Bayes Approach to Optimizing Machine Learning Algorithms', 'Multiscale Quantization for Fast Similarity Search', 'Bregman Divergence for Stochastic Variance Reduction: Saddle-Point and Adversarial Prediction', 'Perturbative Black Box Variational Inference', 'Kernel Feature Selection via Conditional Covariance Minimization', 'Active Learning from Peers', 'On Fairness and Calibration', 'One-Shot Imitation Learning', 'Triangle Generative Adversarial Networks', 'Learning Populations of Parameters', 'Multi-Armed Bandits with Metric Movement Costs', 'Structured Embedding Models for Grouped Data', 'Conservative Contextual Linear Bandits', 'Regularized Modal Regression with Applications in Cognitive Impairment Prediction', 'Adversarial Ranking for Language Generation', 'Diving into the shallows: a computational perspective on large-scale shallow learning', 'Integration Methods and Optimization Algorithms', 'The Unreasonable Effectiveness of Structured Random Orthogonal Embeddings', 'A KL-LUCB algorithm for Large-Scale Crowdsourcing', 'Q-LDA: Uncovering Latent Patterns in Text-based Sequential Decision Processes', 'Streaming Weak Submodularity: Interpreting Neural Networks on the Fly', 'Decomposable Submodular Function Minimization: Discrete and Continuous', 'Learning Affinity via Spatial Propagation Networks', 'Gated Recurrent Convolution Neural Network for OCR', 'Multi-view Matrix Factorization for Linear Dynamical System Estimation', 'Policy Gradient With Value Function Approximation For Collective Multiagent Planning', 'Stochastic Submodular Maximization: The Case of Coverage Functions', 'Stochastic Approximation for Canonical Correlation Analysis', 'Linear regression without correspondence', 'Structured Generative Adversarial Networks', 'Dynamic-Depth Context Tree Weighting', 'Fast, Sample-Efficient Algorithms for Structured Phase Retrieval', 'Hierarchical Methods of Moments', 'A New Alternating Direction Method for Linear Programming', 'Near Optimal Sketching of Low-Rank Tensor Regression', 'Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models', 'Position-based Multiple-play Bandit Problem with Unknown Position Bias', 'Deep Voice 2: Multi-Speaker Neural Text-to-Speech', 'Eigen-Distortions of Hierarchical Representations', 'Learning to Prune Deep Neural Networks via Layer-wise Optimal Brain Surgeon', 'Deliberation Networks: Sequence Generation Beyond One-Pass Decoding', 'Do Deep Neural Networks Suffer from Crowding?', 'Non-Stationary Spectral Kernels', 'Extracting low-dimensional dynamics from multiple large-scale neural population recordings by learning to predict correlations', 'Minimizing a Submodular Function from Samples', 'A graph-theoretic approach to multitasking', 'Adversarial Surrogate Losses for Ordinal Regression', 'Self-Supervised Intrinsic Image Decomposition', 'On-the-fly Operation Batching in Dynamic Computation Graphs', 'Fitting Low-Rank Tensors in Constant Time', 'Random Projection Filter Bank for Time Series Data', 'Dynamic Revenue Sharing', 'Prototypical Networks for Few-shot Learning', 'Unsupervised learning of object frames by dense equivariant image labelling', 'Unified representation of tractography and diffusion-weighted MRI data using sparse multidimensional arrays', 'Random Permutation Online Isotonic Regression', 'PRUNE: Preserving Proximity and Global Ranking for Network Embedding', 'Online to Offline Conversions, Universality and Adaptive Minibatch Sizes', 'Predicting Organic Reaction Outcomes with Weisfeiler-Lehman Network', 'Inferring Generative Model Structure with Static Analysis', 'Influence Maximization with $\\\\varepsilon$-Almost Submodular Threshold Functions', 'Improved Dynamic Regret for Non-degenerate Functions', 'AdaGAN: Boosting Generative Models', 'Large-Scale Quadratically Constrained Quadratic Program via Low-Discrepancy Sequences', 'Graph Matching via Multiplicative Update Algorithm', 'Neural Expectation Maximization', 'Hunt For The Unique, Stable, Sparse And Fast Feature Learning On Graphs', 'Expectation Propagation with Stochastic Kinetic Model in Complex Interaction Systems', 'Welfare Guarantees from Data', 'Semi-supervised Learning with GANs: Manifold Invariance with Improved Inference', 'Houdini: Fooling Deep Structured Visual and Speech Recognition Models with Adversarial Examples', 'Clustering Stable Instances of Euclidean k-means.', 'Attend and Predict: Understanding Gene Regulation by Selective Attention on Chromatin', 'Deep Reinforcement Learning from Human Preferences', 'Subset Selection under Noise', 'PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space', 'Approximation Bounds for Hierarchical Clustering: Average Linkage, Bisecting K-means, and Local Search', 'Thinking Fast and Slow with Deep Learning and Tree Search', 'Learning Combinatorial Optimization Algorithms over Graphs', 'Resurrecting the sigmoid in deep learning through dynamical isometry: theory and practice', 'Adaptive Classification for Prediction Under a Budget', 'Online Convex Optimization with Stochastic Constraints', 'Structured Bayesian Pruning via Log-Normal Multiplicative Noise', 'Clustering with Noisy Queries', 'Compression-aware Training of Deep Networks', 'Maxing and Ranking with Few Assumptions', 'Subspace Clustering via Tangent Cones', 'DropoutNet: Addressing Cold Start in Recommender Systems', 'Unsupervised Image-to-Image Translation Networks', 'SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability', 'Fast Rates for Bandit Optimization with Upper-Confidence Frank-Wolfe', 'Identifying Outlier Arms in Multi-Armed Bandit', 'Discovering Potential Correlations via Hypercontractivity', 'A Dirichlet Mixture Model of Hawkes Processes for Event Sequence Clustering', 'Efficient Approximation Algorithms for Strings Kernel Based Sequence Classification', 'Multi-output Polynomial Networks and Factorization Machines', 'Tractability in Structured Probability Spaces', 'Practical Bayesian Optimization for Model Fitting with Bayesian Adaptive Direct Search', 'Multi-Information Source Optimization', 'Differentially private Bayesian learning on distributed data', 'MMD GAN: Towards Deeper Understanding of Moment Matching Network', 'Convergence of Gradient EM on Multi-component Mixture of Gaussians', 'Bayesian Dyadic Trees and Histograms for  Regression', 'Efficient and Flexible Inference for Stochastic Systems', 'Learning ReLUs via Gradient Descent', 'Learning Graph Representations with Embedding Propagation', 'Formal Guarantees on the Robustness of a Classifier against Adversarial Manipulation', 'Collapsed variational Bayes for Markov jump processes', 'Is the Bellman residual a bad proxy?', 'Efficient Use of Limited-Memory Accelerators for Linear Learning on Heterogeneous Systems', 'Noise-Tolerant Interactive Learning Using Pairwise Comparisons', 'Near-Optimal Edge Evaluation in Explicit Generalized Binomial Graphs', 'Minimal Exploration in Structured Stochastic Bandits', 'Learning Efficient Object Detection Models with Knowledge Distillation', 'Learning Chordal Markov Networks via Branch and Bound', 'Efficient Optimization for Linear Dynamical Systems with Applications to Clustering and Sparse Coding', 'Deep Subspace Clustering Networks', 'Robust Estimation of Neural Signals in Calcium Imaging', 'Fast-Slow Recurrent Neural Networks', 'PredRNN: Recurrent Neural Networks for Predictive Learning using Spatiotemporal LSTMs', 'Dual Discriminator Generative Adversarial Nets', 'Beyond Parity: Fairness Objectives for Collaborative Filtering', 'Multitask Spectral Learning of Weighted Automata', 'A simple neural network module for relational reasoning', 'Toward Robustness against Label Noise in Training Deep Discriminative Neural Networks', 'Stochastic Mirror Descent in Variationally Coherent Optimization Problems', 'Polynomial Codes: an Optimal Design for High-Dimensional Coded Matrix Multiplication', 'From Bayesian Sparsity to Gated Recurrent Nets', 'Compatible Reward Inverse Reinforcement Learning', 'Consistent Robust Regression', 'Scalable Variational Inference for Dynamical Systems', 'Learning multiple visual domains with residual adapters', 'Incorporating Side Information by Adaptive Convolution', 'Hierarchical Clustering Beyond the Worst-Case', 'Sticking the Landing: Simple, Lower-Variance Gradient Estimators for Variational Inference', 'Multiplicative Weights Update with Constant Step-Size in Congestion Games:  Convergence, Limit Cycles and Chaos', 'QMDP-Net: Deep Learning for Planning under Partial Observability', 'Deep Supervised Discrete Hashing', 'Approximation Algorithms for $\\\\ell_0$-Low Rank Approximation', 'ADMM without a Fixed Penalty Parameter: Faster Convergence with New Adaptive Penalization', 'A Learning Error Analysis for Structured Prediction with Approximate Inference', 'Simple strategies for recovering inner products from coarsely quantized random projections', 'Trimmed Density Ratio Estimation', 'Adaptive Batch Size for Safe Policy Gradients', 'Beyond normality: Learning sparse probabilistic graphical models in the non-Gaussian setting', 'REBAR: Low-variance, unbiased gradient estimates for discrete latent variable models', 'Submultiplicative Glivenko-Cantelli and Uniform Convergence of Revenues', 'Tensor Biclustering', 'On the Model Shrinkage Effect of Gamma Process Edge Partition Models', 'Estimating Mutual Information for Discrete-Continuous Mixtures', 'Reconstructing perceived faces from brain activations with deep adversarial neural decoding', 'An inner-loop free solution to inverse problems using deep neural networks', 'A framework for Multi-A(rmed)/B(andit) Testing with Online FDR Control', 'Interactive Submodular Bandit', 'Hash Embeddings for Efficient Word Representations', 'Learning Low-Dimensional Metrics', 'Unsupervised Sequence Classification using Sequential Output Statistics', 'Deep Sets', 'Optimal Shrinkage of Singular Values Under Random Data Contamination', 'Learning Mixture of Gaussians with Streaming Data', 'Learning to Compose Domain-Specific Transformations for Data Augmentation', 'Preventing Gradient Explosions in Gated Recurrent Units', 'Streaming Sparse Gaussian Process Approximations', 'Differentially Private Empirical Risk Minimization Revisited: Faster and More General', 'Unbounded cache model for online language modeling with open vocabulary', 'Shape and Material from Sound', 'On the Consistency of Quick Shift', 'Wasserstein Learning of Deep Generative Point Process Models', 'Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent', 'Protein Interface Prediction using Graph Convolutional Networks', 'Convergence rates of a partition based Bayesian multivariate density estimation method', 'Avoiding Discrimination through Causal Reasoning', 'Alternating Estimation for Structured High-Dimensional Multi-Response Models', 'Multimodal Learning and Reasoning for Visual Question Answering', 'Generative Local Metric Learning for Kernel Regression', 'Overcoming Catastrophic Forgetting by Incremental Moment Matching', 'Can Decentralized Algorithms Outperform Centralized Algorithms? A Case Study for Decentralized Parallel Stochastic Gradient Descent', 'Gradient Descent Can Take Exponential Time to Escape Saddle Points', 'Dual Path Networks', 'Model-based Bayesian inference of neural activity and connectivity from all-optical interrogation of a neural circuit', 'Universal consistency and minimax rates for online Mondrian Forests', 'Gradient Episodic Memory for Continual Learning', 'Variational Inference for Gaussian Process Models with Linear Complexity', 'The Reversible Residual Network: Backpropagation Without Storing Activations', 'Language Modeling with Recurrent Highway Hypernetworks', 'Parametric Simplex Method for Sparse Learning', 'Filtering Variational Objectives', 'Cold-Start Reinforcement Learning with Softmax Policy Gradient', 'Bridging the Gap Between Value and Policy Based Reinforcement Learning', 'Asynchronous Coordinate Descent under More Realistic Assumptions', 'EEG-GRAPH: A Factor-Graph-Based Model for Capturing Spatial, Temporal, and Observational Relationships in Electroencephalograms', 'Natural Value Approximators: Learning when to Trust Past Estimates', 'Active Exploration for Learning Symbolic Representations', 'Balancing information exposure in social networks', 'Nonlinear Acceleration of Stochastic Algorithms', 'Multi-way Interacting Regression via Factorization Machines', 'The Expxorcist: Nonparametric Graphical Models Via Conditional Exponential Densities', 'Generating steganographic images via adversarial training', 'NeuralFDR: Learning Discovery Thresholds from Hypothesis Features', 'A Scale Free Algorithm for Stochastic Bandits with Bounded Kurtosis', 'Value Prediction Network', 'Detrended Partial Cross Correlation for Brain Connectivity Analysis']\n",
            "['Piotr Dabkowski, Yarin Gal', 'Nicolas Courty, Rémi Flamary, Amaury Habrard, Alain Rakotomamonjy', 'Feiping Nie, Xiaoqian Wang, Cheng Deng, Heng Huang', 'Mohammad Haris Baig, Vladlen Koltun, Lorenzo Torresani', 'Robert Mattila, Cristian Rojas, Vikram Krishnamurthy, Bo Wahlberg', 'Soumendu Sundar Mukherjee, Purnamrita Sarkar, Lizhen Lin', 'Nanyang Ye, Zhanxing Zhu, Rafal Mantiuk', 'Omar El Housni, Vineet Goyal', 'Eleni Triantafillou, Richard Zemel, Raquel Urtasun', 'Patrick Rebeschini, Sekhar C. Tatikonda', 'Sean Welleck, Jialin Mao, Kyunghyun Cho, Zheng Zhang', 'Anirban Roychowdhury, Srinivasan Parthasarathy', 'Phillip A. Jang, Andrew Loeb, Matthew Davidow, Andrew G. Wilson', 'Rajat Sen, Ananda Theertha Suresh, Karthikeyan Shanmugam, Alexandros G. Dimakis, Sanjay Shakkottai', 'Mingsheng Long, ZHANGJIE CAO, Jianmin Wang, Philip S. Yu', 'Arya Mazumdar, Barna Saha', 'Andreas Lehrmann, Leonid Sigal', 'Ziyu Wang, Josh S. Merel, Scott E. Reed, Nando de Freitas, Gregory Wayne, Nicolas Heess', 'Idan Schwartz, Alexander Schwing, Tamir Hazan', 'Alessandro Rudi, Luigi Carratino, Lorenzo Rosasco', 'Jason Xu, Eric Chi, Kenneth Lange', 'Youssef Mroueh, Tom Sercu', 'Addison Hu, Sahand Negahban', 'Matthäus Kleindessner, Ulrike von Luxburg', 'Fabian Pedregosa, Rémi Leblond, Simon Lacoste-Julien', 'Guangcan Liu, Qingshan Liu, Xiaotong Yuan', 'Toan Tran, Trung Pham, Gustavo Carneiro, Lyle Palmer, Ian Reid', 'Muhammad Yousefnezhad, Daoqiang Zhang', 'Jiasen Lu, Anitha Kannan, Jianwei Yang, Devi Parikh, Dhruv Batra', 'Jonathan Huggins, Ryan P. Adams, Tamara Broderick', 'Young Hun Jung, Jack Goetz, Ambuj Tewari', 'Yannick Schroecker, Charles L. Isbell', 'Yi Xu, Qihang Lin, Tianbao Yang', 'Wei-Ning Hsu, Yu Zhang, James Glass', 'Isabeau Prémont-Schwarz, Alexander Ilin, Tele Hao, Antti Rasmus, Rinu Boney, Harri Valpola', 'Yee Teh, Victor Bapst, Wojciech M. Czarnecki, John Quan, James Kirkpatrick, Raia Hadsell, Nicolas Heess, Razvan Pascanu', 'arthur flajolet, Patrick Jaillet', 'Yu-Chuan Su, Kristen Grauman', 'Luiz Chamon, Alejandro Ribeiro', 'Fan Yang, Zhilin Yang, William W. Cohen', 'Mert Gurbuzbalaban, Asuman Ozdaglar, Pablo A. Parrilo, Nuri Vanli', 'Michael Hauser, Asok Ray', 'Hanul Shin, Jung Kwon Lee, Jaehong Kim, Jiwon Kim', 'Jeffrey Pennington, Pratik Worah', 'Stefanos Eleftheriadis, Tom Nicholson, Marc Deisenroth, James Hensman', 'Xiaohan Wei, Stanislav Minsker', 'Robert S. Chen, Brendan Lucier, Yaron Singer, Vasilis Syrgkanis', 'Behnam Neyshabur, Srinadh Bhojanapalli, David Mcallester, Nati Srebro', 'Wouter Boomsma, Jes Frellsen', 'Sebastian U. Stich, Anant Raj, Martin Jaggi', 'Long Jin, Justin Lazarow, Zhuowen Tu', 'Harm Van Seijen, Mehdi Fatemi, Joshua Romoff, Romain Laroche, Tavian Barnes, Jeffrey Tsang', 'Chris Russell, Matt J. Kusner, Joshua Loftus, Ricardo Silva', 'Yujia Li, Alexander Schwing, Kuan-Chieh Wang, Richard Zemel', 'Ashkan Panahi, Babak Hassibi', 'Chris Junchi Li, Mengdi Wang, Han Liu, Tong Zhang', 'Cong Han Lim, Stephen Wright', 'Yu-Xiong Wang, Deva Ramanan, Martial Hebert', 'Volodymyr Kuleshov, Stefano Ermon', 'Bikash Joshi, Massih R. Amini, Ioannis Partalas, Franck Iutzeler, Yury Maximov', 'Elad Hazan, Karan Singh, Cyril Zhang', 'Zhenwen Dai, Mauricio Álvarez, Neil Lawrence', 'Wei-Sheng Lai, Jia-Bin Huang, Ming-Hsuan Yang', 'Jonathan Scarlett, Volkan Cevher', 'Christoph Dann, Tor Lattimore, Emma Brunskill', 'Qiang Liu', 'Futoshi Futami, Issei Sato, Masashi Sugiyama', 'Avrim Blum, Nika Haghtalab, Ariel D. Procaccia, Mingda Qiao', 'Chengtao Li, Stefanie Jegelka, Suvrit Sra', 'Mingzhe Wang, Yihe Tang, Jian Wang, Jia Deng', 'Josip Djolonga, Andreas Krause', 'Jin Hyung Lee, David E. Carlson, Hooshmand Shokri Razaghi, Weichi Yao, Georges A. Goetz, Espen Hagen, Eleanor Batty, E.J. Chichilnisky, Gaute T. Einevoll, Liam Paninski', 'Dario Zanca, Marco Gori', 'Amirhossein Taghvaei, Jin W. Kim, Prashant Mehta', 'Masaaki Imaizumi, Takanori Maehara, Kohei Hayashi', 'Justin Fu, John Co-Reyes, Sergey Levine', 'Hao Li, Soham De, Zheng Xu, Christoph Studer, Hanan Samet, Tom Goldstein', 'Mark van der Wilk, Carl Edward Rasmussen, James Hensman', 'Omer Ben-Porat, Moshe Tennenholtz', 'Zelda E. Mariet, Suvrit Sra', 'Takashi Ishida, Gang Niu, Weihua Hu, Masashi Sugiyama', 'Qi Lou, Rina Dechter, Alexander T. Ihler', 'Pratibha Vellanki, Santu Rana, Sunil Gupta, David Rubin, Alessandra Sutti, Thomas Dorin, Murray Height, Paul Sanders, Svetha Venkatesh', 'Mark Rowland, Adrian Weller', 'Bryan McCann, James Bradbury, Caiming Xiong, Richard Socher', 'Arya Mazumdar, Soumyabrata Pal', 'Hyeonwoo Noh, Tackgeun You, Jonghwan Mun, Bohyung Han', 'Saeid Motiian, Quinn Jones, Seyed Iranmanesh, Gianfranco Doretto', 'Taylor W. Killian, Samuel Daulton, George Konidaris, Finale Doshi-Velez', 'Christos Dimitrakakis, David C. Parkes, Goran Radanovic, Paul Tylkin', 'Alexandre Drouin, Toby Hocking, Francois Laviolette', 'Ofer Dekel, arthur flajolet, Nika Haghtalab, Patrick Jaillet', 'Kartik Ahuja, William Zame, Mihaela van der Schaar', 'M. Sevi Baltaoglu, Lang Tong, Qing Zhao', 'Jiaming Song, Shengjia Zhao, Stefano Ermon', 'Anselm Rothe, Brenden M. Lake, Todd Gureckis', 'Hamed Hassani, Mahdi Soltanolkotabi, Amin Karbasi', 'Novi Quadrianto, Viktoriia Sharmanska', 'Bolin Ding, Janardhan Kulkarni, Sergey Yekhanin', 'Matthew Staib, Sebastian Claici, Justin M. Solomon, Stefanie Jegelka', 'Mingrui Liu, Tianbao Yang', 'Alex Kendall, Yarin Gal', 'Erinc Merdivan, Mohammad Reza Loghmani, Matthieu Geist', 'Yuhao Wang, Liam Solus, Karren Yang, Caroline Uhler', 'Chengyue Gong, win-bin huang', 'Kwang-Sung Jun, Aniruddha Bhargava, Robert Nowak, Rebecca Willett', 'Murat Kocaoglu, Karthikeyan Shanmugam, Elias Bareinboim', 'Jonathan Peck, Joris Roels, Bart Goossens, Yvan Saeys', 'Peter Schulam, Suchi Saria', 'Chao Pan, Michael Zhu', 'Julien Pérolat, Joel Z. Leibo, Vinicius Zambaldi, Charles Beattie, Karl Tuyls, Thore Graepel', 'Di He, Hanqing Lu, Yingce Xia, Tao Qin, Liwei Wang, Tie-Yan Liu', 'Jianfei Chen, Chongxuan LI, Yizhong Ru, Jun Zhu', 'Carlton Downey, Ahmed Hefny, Byron Boots, Geoffrey J. Gordon, Boyue Li', 'Jeremiah Liu, Brent Coull', \"Vincent Roulet, Alexandre d'Aspremont\", 'Sara Sabour, Nicholas Frosst, Geoffrey E. Hinton', 'Yunzhu Li, Jiaming Song, Stefano Ermon', 'Vlad Niculae, Mathieu Blondel', 'Tianxiao Shen, Tao Lei, Regina Barzilay, Tommi Jaakkola', 'Emily L. Denton, vighnesh Birodkar', 'Zhengyuan Zhou, Panayotis Mertikopoulos, Nicholas Bambos, Peter W. Glynn, Claire Tomlin', 'Mohammadhossein Bateni, Soheil Behnezhad, Mahsa Derakhshan, MohammadTaghi Hajiaghayi, Raimondas Kiveris, Silvio Lattanzi, Vahab Mirrokni', 'Federico Monti, Michael Bronstein, Xavier Bresson', 'Jinseok Nam, Eneldo Loza Mencía, Hyunwoo J. Kim, Johannes Fürnkranz', 'Richard Nock, Zac Cranko, Aditya K. Menon, Lizhen Qu, Robert C. Williamson', 'Haw-Shiuan Chang, Erik Learned-Miller, Andrew McCallum', 'Kristof Schütt, Pieter-Jan Kindermans, Huziel Enoc Sauceda Felix, Stefan Chmiela, Alexandre Tkatchenko, Klaus-Robert Müller', 'Alex M. Lamb, Devon Hjelm, Yaroslav Ganin, Joseph Paul Cohen, Aaron C. Courville, Yoshua Bengio', 'Yunus Saatci, Andrew G. Wilson', 'Niladri Chatterji, Peter L. Bartlett', 'Weiwei Liu, Xiaobo Shen, Ivor Tsang', \"Andrew Miller, Nick Foti, Alexander D'Amour, Ryan P. Adams\", 'Christopher Srinivasa, Inmar Givoni, Siamak Ravanbakhsh, Brendan J. Frey', 'Eric Balkanski, Umar Syed, Sergei Vassilvitskii', 'Shiyu Chang, Yang Zhang, Wei Han, Mo Yu, Xiaoxiao Guo, Wei Tan, Xiaodong Cui, Michael Witbrock, Mark A. Hasegawa-Johnson, Thomas S. Huang', 'Zhou Lu, Hongming Pu, Feicheng Wang, Zhiqiang Hu, Liwei Wang', 'Dylan Hadfield-Menell, Smitha Milli, Pieter Abbeel, Stuart J. Russell, Anca Dragan', 'Moein Falahatgar, Mesrob I. Ohannessian, Alon Orlitsky, Venkatadheeraj Pichapati', 'Marc Lanctot, Vinicius Zambaldi, Audrunas Gruslys, Angeliki Lazaridou, Karl Tuyls, Julien Perolat, David Silver, Thore Graepel', 'Gabriel Parra, Felipe Tobar', 'Tomer Koren, Roi Livni', 'Liqian Ma, Xu Jia, Qianru Sun, Bernt Schiele, Tinne Tuytelaars, Luc Van Gool', 'Andre Barreto, Will Dabney, Remi Munos, Jonathan J. Hunt, Tom Schaul, Hado P. van Hasselt, David Silver', 'Xingguo Li, Lin Yang, Jason Ge, Jarvis Haupt, Tong Zhang, Tuo Zhao', 'Simon S. Du, Jayanth Koushik, Aarti Singh, Barnabas Poczos', 'Yue Wang, Wei Chen, Yuting Liu, Zhi-Ming Ma, Tie-Yan Liu', 'Adji Bousso Dieng, Dustin Tran, Rajesh Ranganath, John Paisley, David Blei', 'Qinliang Su, xuejun Liao, Lawrence Carin', 'Yuhuai Wu, Elman Mansimov, Roger B. Grosse, Shun Liao, Jimmy Ba', 'Shipra Agrawal, Randy Jia', 'Daniele Calandriello, Alessandro Lazaric, Michal Valko', 'Gang Wang, Georgios Giannakis, Yousef Saad, Jie Chen', 'Chen-Yu Wei, Yi-Te Hong, Chi-Jen Lu', 'Daniil Ryabko', 'Michael Kamp, Mario Boley, Olana Missura, Thomas Gärtner', 'Siavash Arjomand Bigdeli, Matthias Zwicker, Paolo Favaro, Meiguang Jin', 'Anton Osokin, Francis Bach, Simon Lacoste-Julien', 'Alberto Bietti, Julien Mairal', 'Jörg Bornschein, Andriy Mnih, Daniel Zoran, Danilo Jimenez Rezende', 'Nir Levine, Tom Zahavy, Daniel J. Mankowitz, Aviv Tamar, Shie Mannor', 'Amélie Heliou, Johanne Cohen, Panayotis Mertikopoulos', 'Hsiang-Fu Yu, Cho-Jui Hsieh, Qi Lei, Inderjit S. Dhillon', 'Minhyung Cho, Jaehyung Lee', 'Martin Royer', 'Haoran Tang, Rein Houthooft, Davis Foote, Adam Stooke, OpenAI Xi Chen, Yan Duan, John Schulman, Filip DeTurck, Pieter Abbeel', 'Naoya Takeishi, Yoshinobu Kawahara, Takehisa Yairi', 'Tim Roughgarden, Okke Schrijvers', 'Slobodan Mitrovic, Ilija Bogunovic, Ashkan Norouzi-Fard, Jakub M. Tarnawski, Volkan Cevher', 'Jacob Devlin, Rudy R. Bunel, Rishabh Singh, Matthew Hausknecht, Pushmeet Kohli', 'Chuang Wang, Yue Lu', 'Raef Bassily, Kobbi Nissim, Uri Stemmer, Abhradeep Guha Thakurta', 'Dongsheng Li, Chao Chen, Wei Liu, Tun Lu, Ning Gu, Stephen Chu', 'Veeranjaneyulu Sadhanala, Yu-Xiang Wang, James L. Sharpnack, Ryan J. Tibshirani', 'Yoav Wald, Amir Globerson', 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'Ehsan Emamjomeh-Zadeh, David Kempe', 'Maria-Florina F. Balcan, Hongyang Zhang', 'Alireza Aghasi, Afshin Abdi, Nam Nguyen, Justin Romberg', 'Yuandong Tian, Qucheng Gong, Wenling Shang, Yuxin Wu, C. Lawrence Zitnick', 'Priya Donti, Brandon Amos, J. Zico Kolter', \"Guillaume Lample, Neil Zeghidour, Nicolas Usunier, Antoine Bordes, Ludovic DENOYER, Marc'Aurelio Ranzato\", 'Yuchen Pu, Zhe Gan, Ricardo Henao, Chunyuan Li, Shaobo Han, Lawrence Carin', 'Shuang Liu, Olivier Bousquet, Kamalika Chaudhuri', 'Akash Srivastava, Lazar Valkov, Chris Russell, Michael U. Gutmann, Charles Sutton', 'Vikas Garg, Tommi Jaakkola', 'Jonathan Zung, Ignacio Tartavull, Kisuk Lee, H. Sebastian Seung', 'Marcin Andrychowicz, Filip Wolski, Alex Ray, Jonas Schneider, Rachel Fong, Peter Welinder, Bob McGrew, Josh Tobin, OpenAI Pieter Abbeel, Wojciech Zaremba', 'Joel A. Tropp, Alp Yurtsever, Madeleine Udell, Volkan Cevher', 'Lars Mescheder, Sebastian Nowozin, Andreas Geiger', 'Rui Costa, Ioannis Alexandros Assael, Brendan Shillingford, Nando de Freitas, TIm Vogels', 'Seungil You, David Ding, Kevin Canini, Jan Pfeifer, Maya Gupta', 'Adithya M Devraj, Sean Meyn', 'Bo Dai, Dahua Lin', 'Anirudh Goyal ALIAS PARTH GOYAL, Nan Rosemary Ke, Surya Ganguli, Yoshua Bengio', 'Han Zhao, Geoffrey J. Gordon', 'Amit Daniely', 'Gilles Louppe, Michael Kagan, Kyle Cranmer', 'Jason Altschuler, Jonathan Niles-Weed, Philippe Rigollet', 'Yijun Li, Chen Fang, Jimei Yang, Zhaowen Wang, Xin Lu, Ming-Hsuan Yang', 'Xiuyuan Lu, Benjamin Van Roy', 'Piotr Indyk, Ilya Razenshteyn, Tal Wagner', 'Jie Shen, Ping Li', 'Yonatan Geifman, Ran El-Yaniv', 'Liwei Wang, Alexander Schwing, Svetlana Lazebnik', 'Yizhe Zhang, Dinghan Shen, Guoyin Wang, Zhe Gan, Ricardo Henao, Lawrence Carin', 'Jiajun Wu, Erika Lu, Pushmeet Kohli, Bill Freeman, Josh Tenenbaum', 'Yuchen Pu, Weiyao Wang, Ricardo Henao, Liqun Chen, Zhe Gan, Chunyuan Li, Lawrence Carin', 'Michael Habeck', 'Zhuoran Yang, Krishnakumar Balasubramanian, Zhaoran Wang, Han Liu', 'Stéphanie ALLASSONNIERE, Juliette Chevallier, Stephane Oudard', 'Kyuhong Shim, Minjae Lee, Iksoo Choi, Yoonho Boo, Wonyong Sung', 'Constantinos Daskalakis, Nishanth Dikkala, Gautam Kamath', 'Alyson K. Fletcher, Mojtaba Sahraee-Ardakan, Sundeep Rangan, Philip Schniter', 'Andrea Giovannucci, Johannes Friedrich, Matt Kaufman, Anne Churchland, Dmitri Chklovskii, Liam Paninski, Eftychios A. Pnevmatikakis', 'Kristjan Greenewald, Ambuj Tewari, Susan Murphy, Predag Klasnja', 'Sven Peter, Ferran Diego, Fred A. Hamprecht, Boaz Nadler', 'Surbhi Goel, Adam Klivans', 'Adarsh Prasad, Alexandru Niculescu-Mizil, Pradeep K. Ravikumar', 'Evan Racah, Christopher Beckham, Tegan Maharaj, Samira Ebrahimi Kahou, Mr. Prabhat, Chris Pal', 'Manasi Vartak, Arvind Thiagarajan, Conrado Miranda, Jeshua Bratman, Hugo Larochelle', 'Yi Ouyang, Mukul Gagrani, Ashutosh Nayyar, Rahul Jain', 'Weiyang Liu, Yan-Ming Zhang, Xingguo Li, Zhiding Yu, Bo Dai, Tuo Zhao, Le Song', 'Raymond Yeh, Jinjun Xiong, Wen-Mei Hwu, Minh Do, Alexander Schwing', 'Adith Swaminathan, Akshay Krishnamurthy, Alekh Agarwal, Miro Dudik, John Langford, Damien Jose, Imed Zitouni', 'Michal Derezinski, Manfred K. K. Warmuth', 'Songbai Yan, Chicheng Zhang', 'Joseph Geumlek, Shuang Song, Kamalika Chaudhuri', 'Jalil Kazemitabar, Arash Amini, Adam Bloniarz, Ameet S. Talwalkar', 'Nisheeth Srivastava, Edward Vul', 'Suriya Gunasekar, Blake E. Woodworth, Srinadh Bhojanapalli, Behnam Neyshabur, Nati Srebro', 'An Bian, Kfir Levy, Andreas Krause, Joachim M. Buhmann', 'Eran Malach, Shai Shalev-Shwartz', 'Wataru Kumagai', 'Sagie Benaim, Lior Wolf', 'Maximillian Nickel, Douwe Kiela', 'Hongseok Namkoong, John C. Duchi', 'Kevin Lin, James L. Sharpnack, Alessandro Rinaldo, Ryan J. Tibshirani', 'Neil Gallagher, Kyle R. Ulrich, Austin Talbot, Kafui Dzirasa, Lawrence Carin, David E. Carlson', 'Günter Klambauer, Thomas Unterthiner, Andreas Mayr, Sepp Hochreiter', 'Artur Speiser, Jinyao Yan, Evan W. Archer, Lars Buesing, Srinivas C. Turaga, Jakob H. Macke', 'Ofer Meshi, Alexander Schwing', 'Will Hamilton, Zhitao Ying, Jure Leskovec', 'Rowan McAllister, Carl Edward Rasmussen', 'Yaoqing Yang, Pulkit Grover, Soummya Kar', 'Ryan J. Tibshirani', 'Ingmar Kanitscheider, Ila Fiete', 'Zahra Ghodsi, Tianyu Gu, Siddharth Garg', 'Dominique Joncas, Marina Meila, James McQueen', 'Alessandro Rudi, Lorenzo Rosasco', 'Arun Venkatraman, Nicholas Rhinehart, Wen Sun, Lerrel Pinto, Martial Hebert, Byron Boots, Kris Kitani, J. Bagnell', 'Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, Ameet S. Talwalkar', 'AmirEmad Ghassami, Saber Salehkaleybar, Negar Kiyavash, Kun Zhang', 'Søren Dahlgaard, Mathias Knudsen, Mikkel Thorup', 'Tri Dao, Christopher M. De Sa, Christopher Ré', 'Karol Hausman, Yevgen Chebotar, Stefan Schaal, Gaurav Sukhatme, Joseph J. Lim', 'Francesco Locatello, Michael Tschannen, Gunnar Raetsch, Martin Jaggi', 'Arturs Backurs, Piotr Indyk, Ludwig Schmidt', 'Walid Krichene, Peter L. Bartlett', 'Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, Tie-Yan Liu', 'Hongyuan Mei, Jason M. Eisner', 'Jian Wu, Matthias Poloczek, Andrew G. Wilson, Peter Frazier', 'Paul Hongsuck Seo, Andreas Lehrmann, Bohyung Han, Leonid Sigal', 'Can Karakus, Yifan Sun, Suhas Diggavi, Wotao Yin', 'Zhaohan Guo, Philip S. Thomas, Emma Brunskill', 'Rohit Girdhar, Deva Ramanan', 'Ho Chung Law, Christopher Yau, Dino Sejdinovic', 'Antti Tarvainen, Harri Valpola', 'Ryan Lowe, YI WU, Aviv Tamar, Jean Harb, OpenAI Pieter Abbeel, Igor Mordatch', 'Liangpeng Zhang, Ke Tang, Xin Yao', 'Christos Louizos, Karen Ullrich, Max Welling', 'Cameron Musco, David Woodruff', 'Ziming Zhang, Matthew Brand', 'Ahmed M. Alaa, Mihaela van der Schaar', 'Vatsal Sharan, Sham M. Kakade, Percy S. Liang, Gregory Valiant', 'Qing Qu, Yuqian Zhang, Yonina Eldar, John Wright', 'Ashok Cutkosky, Kwabena A. Boahen', 'George Papamakarios, Theo Pavlakou, Iain Murray', 'Dan Alistarh, Demjan Grubic, Jerry Li, Ryota Tomioka, Milan Vojnovic', 'Danijar Hafner, Alexander Irpan, James Davidson, Nicolas Heess', 'Giulia Fanti, Pramod Viswanath', 'Yanbo Fan, Siwei Lyu, Yiming Ying, Baogang Hu', 'Yuan-Ting Hu, Jia-Bin Huang, Alexander Schwing', 'Dipan Pal, Ashwin Kannan, Gautam Arakalgud, Marios Savvides', 'Greg Van Buskirk, Benjamin Raichel, Nicholas Ruozzi', 'Wei Shen, KAI ZHAO, Yilu Guo, Alan L. Yuille', 'Shinji Ito, Daisuke Hatano, Hanna Sumita, Akihiro Yabe, Takuro Fukunaga, Naonori Kakimura, Ken-Ichi Kawarabayashi', 'Yuanyuan Liu, Fanhua Shang, James Cheng, Hong Cheng, Licheng Jiao', 'Dustin Tran, Rajesh Ranganath, David Blei', 'Mainak Jas, Tom Dupré la Tour, Umut Simsekli, Alexandre Gramfort', 'Harm de Vries, Florian Strub, Jeremie Mary, Hugo Larochelle, Olivier Pietquin, Aaron C. Courville', 'Vitaly Kuznetsov, Mehryar Mohri', 'Serhii Havrylov, Ivan Titov', 'Zhen He, Shaobing Gao, Liang Xiao, Daxue Liu, Hangen He, David Barber', 'Zheng Wen, Branislav Kveton, Michal Valko, Sharan Vaswani', 'Ahmet Alacaoglu, Quoc Tran Dinh, Olivier Fercoq, Volkan Cevher', 'Carl Jidling, Niklas Wahlström, Adrian Wills, Thomas B. Schön', 'Michael Eickenberg, Georgios Exarchakis, Matthew Hirn, Stephane Mallat', 'Jacob D. Abernethy, Jun-Kun Wang', 'Roderich Gross, Yue Gu, Wei Li, Melvin Gauci', 'Xiaojie Jin, Huaxin Xiao, Xiaohui Shen, Jimei Yang, Zhe Lin, Yunpeng Chen, Zequn Jie, Jiashi Feng, Shuicheng Yan', 'Zhaobin Kuang, Sinong Geng, David Page', 'Thomas Bonald, Richard Combes', 'Ilias Diakonikolas, Elena Grigorescu, Jerry Li, Abhiram Natarajan, Krzysztof Onak, Ludwig Schmidt', 'Yedid Hoshen', 'Adam Kosiorek, Alex Bewley, Ingmar Posner', 'Wojciech M. Czarnecki, Simon Osindero, Max Jaderberg, Grzegorz Swirszcz, Razvan Pascanu', 'Tomoya Murata, Taiji Suzuki', 'Bo-Jian Hou, Lijun Zhang, Zhi-Hua Zhou', 'Felix Berkenkamp, Matteo Turchetta, Angela Schoellig, Andreas Krause', 'Kristjan Greenewald, Seyoung Park, Shuheng Zhou, Alexander Giessing', 'Andrei-Cristian Barbos, Francois Caron, Jean-François Giovannelli, Arnaud Doucet', 'Liping Liu, Francisco Ruiz, Susan Athey, David Blei', 'Kristofer Bouchard, Alejandro Bujan, Fred Roosta, Shashanka Ubaru, Mr. Prabhat, Antoine Snijders, Jian-Hua Mao, Edward Chang, Michael W. Mahoney, Sharmodeep Bhattacharya', 'Zihang Dai, Zhilin Yang, Fan Yang, William W. Cohen, Russ R. Salakhutdinov', 'Yitong Li, michael Murias, samantha Major, geraldine Dawson, Kafui Dzirasa, Lawrence Carin, David E. Carlson', 'Anton Mallasto, Aasa Feragen', 'Holakou Rahmanian, Manfred K. K. Warmuth', 'Aaron van den Oord, Oriol Vinyals, koray kavukcuoglu', 'Haizi Yu, Tianxi Li, Lav R. Varshney', 'Marco Fraccaro, Simon Kamronn, Ulrich Paquet, Ole Winther', 'Kevin Roth, Aurelien Lucchi, Sebastian Nowozin, Thomas Hofmann', 'Francesco Orabona, Tatiana Tommasi', 'Jian Zhao, Lin Xiong, Panasonic Karlekar Jayashree, Jianshu Li, Fang Zhao, Zhecan Wang, Panasonic Sugiri Pranata, Panasonic Shengmei Shen, Shuicheng Yan, Jiashi Feng', 'Christian Borgs, Jennifer Chayes, Christina E. Lee, Devavrat Shah', 'Ryuichi Kiryo, Gang Niu, Marthinus C. du Plessis, Masashi Sugiyama', 'Vaishnavh Nagarajan, J. Zico Kolter', 'Cong Fang, Feng Cheng, Zhouchen Lin', 'Hong Chen, Xiaoqian Wang, Cheng Deng, Heng Huang', 'Alireza Makhzani, Brendan J. Frey', 'Rishit Sheth, Roni Khardon', 'Aaditya Ramdas, Fanny Yang, Martin J. Wainwright, Michael I. Jordan', 'Noam Brown, Tuomas Sandholm', 'Ben London', 'El Mahdi El Mhamdi, Rachid Guerraoui, Hadrien Hendrikx, Alexandre Maurer', 'Jun-Yan Zhu, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei A. Efros, Oliver Wang, Eli Shechtman', 'Ashia C. Wilson, Rebecca Roelofs, Mitchell Stern, Nati Srebro, Benjamin Recht', 'Ge Yang, Samuel Schoenholz', 'Lihua Lei, Cheng Ju, Jianbo Chen, Michael I. Jordan', 'Aryan Mokhtari, Alejandro Ribeiro', 'Hugh Salimbeni, Marc Deisenroth', 'Muhammad Bilal Zafar, Isabel Valera, Manuel Rodriguez, Krishna Gummadi, Adrian Weller', 'Ilja Kuzborskij, Nicolò Cesa-Bianchi', 'Alberto Bietti, Julien Mairal', 'Anastasiia Mishchuk, Dmytro Mishkin, Filip Radenovic, Jiri Matas', 'Shumeet Baluja', 'Remi Lam, Karen Willcox', 'Mehryar Mohri, Scott Yang', 'Alejandro Newell, Jia Deng', 'Chaobing Song, Shaobo Cui, Yong Jiang, Shu-Tao Xia', 'Aurko Roy, Huan Xu, Sebastian Pokutta', 'Yarin Gal, Jiri Hron, Alex Kendall', 'Yi Ding, Risi Kondor, Jonathan Eskreis-Winkler', 'Yasin Abbasi Yadkori, Peter L. Bartlett, Victor Gabillon', 'Chris Metzler, Ali Mousavi, Richard Baraniuk', '', 'Tatsunori B. Hashimoto, Percy S. Liang, John C. Duchi', 'Eirikur Agustsson, Fabian Mentzer, Michael Tschannen, Lukas Cavigelli, Radu Timofte, Luca Benini, Luc V. Gool', 'Katrina Ligett, Seth Neel, Aaron Roth, Bo Waggoner, Steven Z. Wu', 'Chongxuan LI, Taufik Xu, Jun Zhu, Bo Zhang', 'Christoph Hofer, Roland Kwitt, Marc Niethammer, Andreas Uhl', 'Andres Munoz, Sergei Vassilvitskii', 'Mali Sundaresan, Arshed Nabeel, Devarajan Sridharan', 'Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, Aaron C. Courville', 'Benjamin Cowley, Ryan Williamson, Katerina Clemens, Matthew Smith, Byron M. Yu', 'Ashish Khetan, Sewoong Oh', 'Simon S. Du, Yining Wang, Aarti Singh', 'Wei Wen, Cong Xu, Feng Yan, Chunpeng Wu, Yandan Wang, Yiran Chen, Hai Li', 'Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, Sepp Hochreiter', 'Scott M. Lundberg, Su-In Lee', 'Emmanuel Abbe, Sanjeev Kulkarni, Eun Jee Lee', 'Zeyuan Allen-Zhu, Elad Hazan, Wei Hu, Yuanzhi Li', 'Roel Dobbe, David Fridovich-Keil, Claire Tomlin', 'David Klindt, Alexander S. Ecker, Thomas Euler, Matthias Bethge', 'Ksenia Konyushkova, Raphael Sznitman, Pascal Fua', 'Qizhe Xie, Zihang Dai, Yulun Du, Eduard Hovy, Graham Neubig', 'Nicholas Watters, Daniel Zoran, Theophane Weber, Peter Battaglia, Razvan Pascanu, Andrea Tacchetti', 'Kareem Amin, Nan Jiang, Satinder Singh', 'Murat A. Erdogdu, Yash Deshpande, Andrea Montanari', 'Sung-Soo Ahn, Michael Chertkov, Jinwoo Shin', 'huan ling, Sanja Fidler', 'Alejandro Newell, Zhiao Huang, Jia Deng', 'Linus Hamilton, Frederic Koehler, Ankur Moitra', 'Ehsan Elhamifar, M. Clara De Paolis Kaluza', 'Anirudh Goyal ALIAS PARTH GOYAL, Alessandro Sordoni, Marc-Alexandre Côté, Nan Rosemary Ke, Yoshua Bengio', 'Ronan Fruit, Matteo Pirotta, Alessandro Lazaric, Emma Brunskill', 'Asish Ghoshal, Jean Honorio', 'Arthur Mensch, Julien Mairal, Danilo Bzdok, Bertrand Thirion, Gael Varoquaux', 'Mikhail Yurochkin, Aritra Guha, XuanLong Nguyen', 'Yingxiang Yang, Jalal Etesami, Niao He, Negar Kiyavash', 'Maximilian Alber, Pieter-Jan Kindermans, Kristof Schütt, Klaus-Robert Müller, Fei Sha', 'Aryeh Kontorovich, Sivan Sabato, Roi Weiss', 'Christos Louizos, Uri Shalit, Joris M. Mooij, David Sontag, Richard Zemel, Max Welling', 'Emmanouil Platanios, Hoifung Poon, Tom M. Mitchell, Eric J. Horvitz', 'Miro Dudik, Sebastien Lahaie, Ryan M. Rogers, Jennifer Wortman Vaughan', 'Stéphan Clémençon, Mastane Achab', 'Kun Dong, David Eriksson, Hannes Nickisch, David Bindel, Andrew G. Wilson', 'Flavio Chierichetti, Ravi Kumar, Silvio Lattanzi, Sergei Vassilvitskii', 'Wittawat Jitkrittum, Wenkai Xu, Zoltan Szabo, Kenji Fukumizu, Arthur Gretton', 'Nir Levine, Koby Crammer, Shie Mannor', 'Ga Wu, Buser Say, Scott Sanner', 'Chris Oates, Steven Niederer, Angela Lee, François-Xavier Briol, Mark Girolami', 'Julien Audiffren, Liva Ralaivola', 'Mohammad Ali Bashiri, Xinhua Zhang', 'Daniel Milstein, Jason Pacheco, Leigh Hochberg, John D. Simeral, Beata Jarosiewicz, Erik Sudderth', 'Jeffrey Regier, Michael I. Jordan, Jon McAuliffe', 'Lixin Fan', 'Flavio Calmon, Dennis Wei, Bhanukiran Vinzamuri, Karthikeyan Natesan Ramamurthy, Kush R. Varshney', 'Jinfeng Yi, Cho-Jui Hsieh, Kush R. Varshney, Lijun Zhang, Yao Li', 'Abhishek Kar, Christian Häne, Jitendra Malik', 'Krzysztof M. Choromanski, Vikas Sindhwani', 'Siddharth N, Brooks Paige, Jan-Willem van de Meent, Alban Desmaison, Noah Goodman, Pushmeet Kohli, Frank Wood, Philip Torr', 'Luca Ambrogioni, Max Hinne, Marcel Van Gerven, Eric Maris', 'Jacob Steinhardt, Pang Wei W. Koh, Percy S. Liang', 'Aravind Rajeswaran, Kendall Lowrey, Emanuel V. Todorov, Sham M. Kakade', 'Sébastien Racanière, Theophane Weber, David Reichert, Lars Buesing, Arthur Guez, Danilo Jimenez Rezende, Adrià Puigdomènech Badia, Oriol Vinyals, Nicolas Heess, Yujia Li, Razvan Pascanu, Peter Battaglia, Demis Hassabis, David Silver, Daan Wierstra', 'Balaji Lakshminarayanan, Alexander Pritzel, Charles Blundell', 'Fabio Cecchi, Nidhi Hegde', 'Xiangru Huang, Zhenxiao Liang, Chandrajit Bajaj, Qixing Huang', 'Yossi Arjevani', 'Urs Köster, Tristan Webb, Xin Wang, Marcel Nassar, Arjun K. Bansal, William Constable, Oguz Elibol, Scott Gray, Stewart Hall, Luke Hornof, Amir Khosrowshahi, Carey Kloss, Ruby J. Pai, Naveen Rao', 'Cameron Musco, Christopher Musco', 'Yuting Wei, Fanny Yang, Martin J. Wainwright', 'Shixiang (Shane) Gu, Timothy Lillicrap, Richard E. Turner, Zoubin Ghahramani, Bernhard Schölkopf, Sergey Levine', 'Dylan J. Foster, Satyen Kale, Mehryar Mohri, Karthik Sridharan', 'Yichen Wang, Xiaojing Ye, Hongyuan Zha, Le Song', 'Eric Balkanski, Nicole Immorlica, Yaron Singer', 'John T. Halloran, David M. Rocke', 'Rong Ge, Tengyu Ma', 'Matt J. Kusner, Joshua Loftus, Chris Russell, Ricardo Silva', 'Dan Garber', 'Pan Li, Olgica Milenkovic', 'Ji Lin, Yongming Rao, Jiwen Lu, Jie Zhou', 'Elad Hoffer, Itay Hubara, Daniel Soudry', 'Emilie Kaufmann, Wouter M. Koolen', 'Xingjian Shi, Zhihan Gao, Leonard Lausen, Hao Wang, Dit-Yan Yeung, Wai-kin Wong, Wang-chun WOO', 'Zhao Song, Yusuke Muraoka, Ryohei Fujimaki, Lawrence Carin', 'Zhanhong Jiang, Aditya Balu, Chinmay Hegde, Soumik Sarkar', 'Le Song, Santosh Vempala, John Wilmes, Bo Xie', 'Vasilis Syrgkanis', 'Ahmad Beirami, Meisam Razaviyayn, Shahin Shahrampour, Vahid Tarokh', 'James Newling, François Fleuret', 'Dan Xu, Wanli Ouyang, Xavier Alameda-Pineda, Elisa Ricci, Xiaogang Wang, Nicu Sebe', 'Shixiang Chen, Shiqian Ma, Wei Liu', 'Zelun Luo, Yuliang Zou, Judy Hoffman, Li F. Fei-Fei', 'Qinshi Wang, Wei Chen', 'Nikolay Savinov, Lubor Ladicky, Marc Pollefeys', 'Yuanzhi Li, Yang Yuan', 'Giuseppe Pica, Eugenio Piasini, Houman Safaai, Caroline Runyan, Christopher Harvey, Mathew Diamond, Christoph Kayser, Tommaso Fellin, Stefano Panzeri', 'Hsiao-Yu Tung, Hsiao-Wei Tung, Ersin Yumer, Katerina Fragkiadaki', 'Chengxu Zhuang, Jonas Kubilius, Mitra JZ Hartmann, Daniel L. Yamins', 'Cyrus Rashtchian, Konstantin Makarychev, Miklos Racz, Siena Ang, Djordje Jevdjic, Sergey Yekhanin, Luis Ceze, Karin Strauss', 'Marco Cusumano-Towner, Vikash K. Mansinghka', 'Aolin Xu, Maxim Raginsky', 'Jiajun Wu, Yifan Wang, Tianfan Xue, Xingyuan Sun, Bill Freeman, Josh Tenenbaum', 'Jan-Matthis Lueckmann, Pedro J. Goncalves, Giacomo Bassetto, Kaan Öcal, Marcel Nonnenmacher, Jakob H. Macke', 'Chunyuan Li, Hao Liu, Changyou Chen, Yuchen Pu, Liqun Chen, Ricardo Henao, Lawrence Carin', 'Pan Xu, Jian Ma, Quanquan Gu', 'Sven Peter, Elke Kirschbaum, Martin Both, Lee Campbell, Brandon Harvey, Conor Heins, Daniel Durstewitz, Ferran Diego, Fred A. Hamprecht', 'Nikhil Parthasarathy, Eleanor Batty, William Falcon, Thomas Rutten, Mohit Rajpal, E.J. Chichilnisky, Liam Paninski', 'Caglar Gulcehre, Francis Dutil, Adam Trischler, Yoshua Bengio', 'Yonatan Belinkov, James Glass', 'Aniket Anand Deshmukh, Urun Dogan, Clay Scott', 'Prateep Bhattacharjee, Sukhendu Das', 'Chao Qin, Diego Klabjan, Daniel Russo', 'Xiaofan Lin, Cong Zhao, Wei Pan', 'Peter L. Bartlett, Dylan J. Foster, Matus J. Telgarsky', 'Carlo Ciliberto, Alessandro Rudi, Lorenzo Rosasco, Massimiliano Pontil', 'Seunghyun Park, Seonwoo Min, Hyun-Soo Choi, Sungroh Yoon', 'Nicolò Cesa-Bianchi, Claudio Gentile, Gabor Lugosi, Gergely Neu', 'Tim Rocktäschel, Sebastian Riedel', 'Sheng Li, Yun Fu', 'Nicolò Colombo, Ricardo Silva, Soong Moon Kang', 'Anqi Wu, Nicholas A. Roy, Stephen Keeley, Jonathan W. Pillow', 'Guy Uziel, Ran El-Yaniv', 'Minje Jang, Sunghyun Kim, Changho Suh, Sewoong Oh', 'Cheng Li, Felix MF Wong, Zhenming Liu, Varun Kanade', 'James McInerney', 'Xiang Wu, Ruiqi Guo, Ananda Theertha Suresh, Sanjiv Kumar, Daniel N. Holtmann-Rice, David Simcha, Felix Yu', 'Zhan Shi, Xinhua Zhang, Yaoliang Yu', 'Robert Bamler, Cheng Zhang, Manfred Opper, Stephan Mandt', 'Jianbo Chen, Mitchell Stern, Martin J. Wainwright, Michael I. Jordan', 'Keerthiram Murugesan, Jaime Carbonell', 'Geoff Pleiss, Manish Raghavan, Felix Wu, Jon Kleinberg, Kilian Q. Weinberger', 'Yan Duan, Marcin Andrychowicz, Bradly Stadie, OpenAI Jonathan Ho, Jonas Schneider, Ilya Sutskever, Pieter Abbeel, Wojciech Zaremba', 'Zhe Gan, Liqun Chen, Weiyao Wang, Yuchen Pu, Yizhe Zhang, Hao Liu, Chunyuan Li, Lawrence Carin', 'Kevin Tian, Weihao Kong, Gregory Valiant', 'Tomer Koren, Roi Livni, Yishay Mansour', 'Maja Rudolph, Francisco Ruiz, Susan Athey, David Blei', 'Abbas Kazerouni, Mohammad Ghavamzadeh, Yasin Abbasi Yadkori, Benjamin Van Roy', 'Xiaoqian Wang, Hong Chen, Weidong Cai, Dinggang Shen, Heng Huang', 'Kevin Lin, Dianqi Li, Xiaodong He, Zhengyou Zhang, Ming-ting Sun', 'SIYUAN MA, Mikhail Belkin', \"Damien Scieur, Vincent Roulet, Francis Bach, Alexandre d'Aspremont\", 'Krzysztof M. Choromanski, Mark Rowland, Adrian Weller', 'Ervin Tanczos, Robert Nowak, Bob Mankoff', 'Jianshu Chen, Chong Wang, Lin Xiao, Ji He, Lihong Li, Li Deng', 'Ethan Elenberg, Alexandros G. Dimakis, Moran Feldman, Amin Karbasi', 'Alina Ene, Huy Nguyen, László A. Végh', 'Sifei Liu, Shalini De Mello, Jinwei Gu, Guangyu Zhong, Ming-Hsuan Yang, Jan Kautz', 'Jianfeng Wang, Xiaolin Hu', 'Mahdi Karami, Martha White, Dale Schuurmans, Csaba Szepesvari', 'Duc Thien Nguyen, Akshat Kumar, Hoong Chuin Lau', 'Mohammad Karimi, Mario Lucic, Hamed Hassani, Andreas Krause', 'Raman Arora, Teodor Vanislavov Marinov, Poorya Mianjy, Nati Srebro', 'Daniel J. Hsu, Kevin Shi, Xiaorui Sun', 'Zhijie Deng, Hao Zhang, Xiaodan Liang, Luona Yang, Shizhen Xu, Jun Zhu, Eric P. Xing', 'Joao V. Messias, Shimon Whiteson', 'Gauri Jagatap, Chinmay Hegde', 'Matteo Ruffini, Guillaume Rabusseau, Borja Balle', 'Sinong Wang, Ness Shroff', 'Xingguo Li, Jarvis Haupt, David Woodruff', 'Sergey Ioffe', 'Junpei Komiyama, Junya Honda, Akiko Takeda', 'Andrew Gibiansky, Sercan Arik, Gregory Diamos, John Miller, Kainan Peng, Wei Ping, Jonathan Raiman, Yanqi Zhou', 'Alexander Berardino, Valero Laparra, Johannes Ballé, Eero Simoncelli', 'Xin Dong, Shangyu Chen, Sinno Pan', 'Yingce Xia, Fei Tian, Lijun Wu, Jianxin Lin, Tao Qin, Nenghai Yu, Tie-Yan Liu', 'Anna Volokitin, Gemma Roig, Tomaso A. Poggio', 'Sami Remes, Markus Heinonen, Samuel Kaski', 'Marcel Nonnenmacher, Srinivas C. Turaga, Jakob H. Macke', 'Eric Balkanski, Yaron Singer', 'Noga Alon, Daniel Reichman, Igor Shinkar, Tal Wagner, Sebastian Musslick, Jonathan D. Cohen, Tom Griffiths, Biswadip dey, Kayhan Ozcimder', 'Rizal Fathony, Mohammad Ali Bashiri, Brian Ziebart', 'Michael Janner, Jiajun Wu, Tejas D. Kulkarni, Ilker Yildirim, Josh Tenenbaum', 'Graham Neubig, Yoav Goldberg, Chris Dyer', 'Kohei Hayashi, Yuichi Yoshida', 'Amir-massoud Farahmand, Sepideh Pourazarm, Daniel Nikovski', 'Santiago Balseiro, Max Lin, Vahab Mirrokni, Renato Leme, IIIS Song Zuo', 'Jake Snell, Kevin Swersky, Richard Zemel', 'James Thewlis, Hakan Bilen, Andrea Vedaldi', 'Cesar F. Caiafa, Olaf Sporns, Andrew Saykin, Franco Pestilli', 'Wojciech Kotlowski, Wouter M. Koolen, Alan Malek', 'Yi-An Lai, Chin-Chi Hsu, Wen Hao Chen, Mi-Yen Yeh, Shou-De Lin', 'Kfir Levy', 'Wengong Jin, Connor Coley, Regina Barzilay, Tommi Jaakkola', 'Paroma Varma, Bryan D. He, Payal Bajaj, Nishith Khandwala, Imon Banerjee, Daniel Rubin, Christopher Ré', 'Qiang Li, Wei Chen, Institute of Computing Xiaoming Sun, Institute of Computing Jialin Zhang', 'Lijun Zhang, Tianbao Yang, Jinfeng Yi, Rong Jin, Zhi-Hua Zhou', 'Ilya O. Tolstikhin, Sylvain Gelly, Olivier Bousquet, Carl-Johann SIMON-GABRIEL, Bernhard Schölkopf', 'Kinjal Basu, Ankan Saha, Shaunak Chatterjee', 'Bo Jiang, Jin Tang, Chris Ding, Yihong Gong, Bin Luo', 'Klaus Greff, Sjoerd van Steenkiste, Jürgen Schmidhuber', 'Saurabh Verma, Zhi-Li Zhang', 'Le Fang, Fan Yang, Wen Dong, Tong Guan, Chunming Qiao', 'Darrell Hoy, Denis Nekipelov, Vasilis Syrgkanis', 'Abhishek Kumar, Prasanna Sattigeri, Tom Fletcher', 'Moustapha M. Cisse, Yossi Adi, Natalia Neverova, Joseph Keshet', 'Aravindan Vijayaraghavan, Abhratanu Dutta, Alex Wang', 'Ritambhara Singh, Jack Lanchantin, Arshdeep Sekhon, Yanjun Qi', 'Paul F. Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, Dario Amodei', 'Chao Qian, Jing-Cheng Shi, Yang Yu, Ke Tang, Zhi-Hua Zhou', 'Charles Ruizhongtai Qi, Li Yi, Hao Su, Leonidas J. Guibas', 'Benjamin Moseley, Joshua Wang', 'Thomas Anthony, Zheng Tian, David Barber', 'Elias Khalil, Hanjun Dai, Yuyu Zhang, Bistra Dilkina, Le Song', 'Jeffrey Pennington, Samuel Schoenholz, Surya Ganguli', 'Feng Nan, Venkatesh Saligrama', 'Hao Yu, Michael Neely, Xiaohan Wei', 'Kirill Neklyudov, Dmitry Molchanov, Arsenii Ashukha, Dmitry P. Vetrov', 'Arya Mazumdar, Barna Saha', 'Jose M. Alvarez, Mathieu Salzmann', 'Moein Falahatgar, Yi Hao, Alon Orlitsky, Venkatadheeraj Pichapati, Vaishakh Ravindrakumar', 'Amin Jalali, Rebecca Willett', 'Maksims Volkovs, Guangwei Yu, Tomi Poutanen', 'Ming-Yu Liu, Thomas Breuel, Jan Kautz', 'Maithra Raghu, Justin Gilmer, Jason Yosinski, Jascha Sohl-Dickstein', 'Quentin Berthet, Vianney Perchet', 'Honglei Zhuang, Chi Wang, Yifan Wang', 'Hyeji Kim, Weihao Gao, Sreeram Kannan, Sewoong Oh, Pramod Viswanath', 'Hongteng Xu, Hongyuan Zha', 'Muhammad Farhan, Juvaria Tariq, Arif Zaman, Mudassir Shabbir, Imdad Ullah Khan', 'Mathieu Blondel, Vlad Niculae, Takuma Otsuka, Naonori Ueda', 'Arthur Choi, Yujia Shen, Adnan Darwiche', 'Luigi Acerbi, Wei Ji Ma', 'Matthias Poloczek, Jialei Wang, Peter Frazier', 'Mikko Heikkilä, Eemil Lagerspetz, Samuel Kaski, Kana Shimizu, Sasu Tarkoma, Antti Honkela', 'Chun-Liang Li, Wei-Cheng Chang, Yu Cheng, Yiming Yang, Barnabas Poczos', 'Bowei Yan, Mingzhang Yin, Purnamrita Sarkar', 'Stéphanie van der Pas, Veronika Ročková', 'Stefan Bauer, Nico S. Gorbach, Djordje Miladinovic, Joachim M. Buhmann', 'Mahdi Soltanolkotabi', 'Alberto Garcia Duran, Mathias Niepert', 'Matthias Hein, Maksym Andriushchenko', 'Boqian Zhang, Jiangwei Pan, Vinayak A. Rao', 'Matthieu Geist, Bilal Piot, Olivier Pietquin', 'Celestine Dünner, Thomas Parnell, Martin Jaggi', 'Yichong Xu, Hongyang Zhang, Kyle Miller, Aarti Singh, Artur Dubrawski', 'Sanjiban Choudhury, Shervin Javdani, Siddhartha Srinivasa, Sebastian Scherer', 'Richard Combes, Stefan Magureanu, Alexandre Proutiere', 'Guobin Chen, Wongun Choi, Xiang Yu, Tony Han, Manmohan Chandraker', 'Kari Rantanen, Antti Hyttinen, Matti Järvisalo', 'Wenbing Huang, Mehrtash Harandi, Tong Zhang, Lijie Fan, Fuchun Sun, Junzhou Huang', 'Pan Ji, Tong Zhang, Hongdong Li, Mathieu Salzmann, Ian Reid', 'Hakan Inan, Murat A. Erdogdu, Mark Schnitzer', 'Asier Mujika, Florian Meier, Angelika Steger', 'Yunbo Wang, Mingsheng Long, Jianmin Wang, Zhifeng Gao, Philip S. Yu', 'Tu Nguyen, Trung Le, Hung Vu, Dinh Phung', 'Sirui Yao, Bert Huang', 'Guillaume Rabusseau, Borja Balle, Joelle Pineau', 'Adam Santoro, David Raposo, David G. Barrett, Mateusz Malinowski, Razvan Pascanu, Peter Battaglia, Timothy Lillicrap', 'Arash Vahdat', 'Zhengyuan Zhou, Panayotis Mertikopoulos, Nicholas Bambos, Stephen Boyd, Peter W. Glynn', 'Qian Yu, Mohammad Maddah-Ali, Salman Avestimehr', 'Hao He, Bo Xin, Satoshi Ikehata, David Wipf', 'Alberto Maria Metelli, Matteo Pirotta, Marcello Restelli', 'Kush Bhatia, Prateek Jain, Parameswaran Kamalaruban, Purushottam Kar', 'Nico S. Gorbach, Stefan Bauer, Joachim M. Buhmann', 'Sylvestre-Alvise Rebuffi, Hakan Bilen, Andrea Vedaldi', 'Di Kang, Debarun Dhar, Antoni Chan', 'Vincent Cohen-Addad, Varun Kanade, Frederik Mallmann-Trenn', 'Geoffrey Roeder, Yuhuai Wu, David K. Duvenaud', 'Gerasimos Palaiopanos, Ioannis Panageas, Georgios Piliouras', 'Peter Karkus, David Hsu, Wee Sun Lee', 'Qi Li, Zhenan Sun, Ran He, Tieniu Tan', 'Karl Bringmann, Pavel Kolev, David Woodruff', 'Yi Xu, Mingrui Liu, Qihang Lin, Tianbao Yang', 'Yuanbin Wu, Man Lan, Shiliang Sun, Qi Zhang, Xuanjing Huang', 'Ping Li, Martin Slawski', 'Song Liu, Akiko Takeda, Taiji Suzuki, Kenji Fukumizu', 'Matteo Papini, Matteo Pirotta, Marcello Restelli', 'Rebecca Morrison, Ricardo Baptista, Youssef Marzouk', 'George Tucker, Andriy Mnih, Chris J. Maddison, John Lawson, Jascha Sohl-Dickstein', 'Noga Alon, Moshe Babaioff, Yannai A. Gonczarowski, Yishay Mansour, Shay Moran, Amir Yehudayoff', 'Soheil Feizi, Hamid Javadi, David Tse', 'Iku Ohama, Issei Sato, Takuya Kida, Hiroki Arimura', 'Weihao Gao, Sreeram Kannan, Sewoong Oh, Pramod Viswanath', 'Yağmur Güçlütürk, Umut Güçlü, Katja Seeliger, Sander Bosch, Rob van Lier, Marcel A. J. van Gerven', 'Kai Fan, Qi Wei, Lawrence Carin, Katherine A. Heller', 'Fanny Yang, Aaditya Ramdas, Kevin G. Jamieson, Martin J. Wainwright', 'Lin Chen, Andreas Krause, Amin Karbasi', 'Dan Tito Svenstrup, Jonas Hansen, Ole Winther', 'Blake Mason, Lalit Jain, Robert Nowak', 'Yu Liu, Jianshu Chen, Li Deng', 'Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Russ R. Salakhutdinov, Alexander J. Smola', 'Danny Barash, Matan Gavish', 'Aditi Raghunathan, Prateek Jain, Ravishankar Krishnawamy', 'Alexander J. Ratner, Henry Ehrenberg, Zeshan Hussain, Jared Dunnmon, Christopher Ré', 'Sekitoshi Kanai, Yasuhiro Fujiwara, Sotetsu Iwamura', 'Thang D. Bui, Cuong Nguyen, Richard E. Turner', 'Di Wang, Minwei Ye, Jinhui Xu', 'Edouard Grave, Moustapha M. Cisse, Armand Joulin', 'Zhoutong Zhang, Qiujia Li, Zhengjia Huang, Jiajun Wu, Josh Tenenbaum, Bill Freeman', 'Heinrich Jiang', 'Shuai Xiao, Mehrdad Farajtabar, Xiaojing Ye, Junchi Yan, Le Song, Hongyuan Zha', 'Peva Blanchard, El Mahdi El Mhamdi, Rachid Guerraoui, Julien Stainer', 'Alex Fout, Jonathon Byrd, Basir Shariat, Asa Ben-Hur', 'Linxi Liu, Dangna Li, Wing Hung Wong', 'Niki Kilbertus, Mateo Rojas Carulla, Giambattista Parascandolo, Moritz Hardt, Dominik Janzing, Bernhard Schölkopf', 'Sheng Chen, Arindam Banerjee', 'Ilija Ilievski, Jiashi Feng', 'Yung-Kyun Noh, Masashi Sugiyama, Kee-Eung Kim, Frank Park, Daniel D. Lee', 'Sang-Woo Lee, Jin-Hwa Kim, Jaehyun Jun, Jung-Woo Ha, Byoung-Tak Zhang', 'Xiangru Lian, Ce Zhang, Huan Zhang, Cho-Jui Hsieh, Wei Zhang, Ji Liu', 'Simon S. Du, Chi Jin, Jason D. Lee, Michael I. Jordan, Aarti Singh, Barnabas Poczos', 'Yunpeng Chen, Jianan Li, Huaxin Xiao, Xiaojie Jin, Shuicheng Yan, Jiashi Feng', 'Laurence Aitchison, Lloyd Russell, Adam M. Packer, Jinyao Yan, Philippe Castonguay, Michael Hausser, Srinivas C. Turaga', 'Jaouad Mourtada, Stéphane Gaïffas, Erwan Scornet', \"David Lopez-Paz, Marc'Aurelio Ranzato\", 'Ching-An Cheng, Byron Boots', 'Aidan N. Gomez, Mengye Ren, Raquel Urtasun, Roger B. Grosse', 'Joseph Suarez', 'Haotian Pang, Han Liu, Robert J. Vanderbei, Tuo Zhao', 'Chris J. Maddison, John Lawson, George Tucker, Nicolas Heess, Mohammad Norouzi, Andriy Mnih, Arnaud Doucet, Yee Teh', 'Nan Ding, Radu Soricut', 'Ofir Nachum, Mohammad Norouzi, Kelvin Xu, Dale Schuurmans', 'Tao Sun, Robert Hannah, Wotao Yin', 'Yogatheesan Varatharajah, Min Jin Chong, Krishnakant Saboo, Brent Berry, Benjamin Brinkmann, Gregory Worrell, Ravishankar Iyer', 'Zhongwen Xu, Joseph Modayil, Hado P. van Hasselt, Andre Barreto, David Silver, Tom Schaul', 'Garrett Andersen, George Konidaris', 'Kiran Garimella, Aristides Gionis, Nikos Parotsidis, Nikolaj Tatti', \"Damien Scieur, Francis Bach, Alexandre d'Aspremont\", 'Mikhail Yurochkin, XuanLong Nguyen, nikolaos Vasiloglou', 'Arun Suggala, Mladen Kolar, Pradeep K. Ravikumar', 'Jamie Hayes, George Danezis', 'Fei Xia, Martin J. Zhang, James Y. Zou, David Tse', 'Tor Lattimore', 'Junhyuk Oh, Satinder Singh, Honglak Lee', 'Jaime Ide, Fábio Cappabianco, Fabio Faria, Chiang-shan R. Li']\n",
            "['https://papers.nips.cc//paper/2017/hash/0060ef47b12160b9198302ebdb144dcf-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/0070d23b06b1486a538c0eaa45dd167a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/00a03ec6533ca7f5c644d198d815329c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/013a006f03dbc5392effeb8f18fda755-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/01894d6f048493d2cacde3c579c315a3-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/018dd1e07a2de4a08e6612341bf2323e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/019d385eb67632a7e958e23f24bd07d7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/01a0683665f38d8e5e567b3b15ca98bf-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/01e9565cecc4e989123f9620c1d09c09-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/024d7f84fff11dd7e8d9c510137a2381-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/028ee724157b05d04e7bdcf237d12e60-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/02a32ad2669e6fe298e607fe7cc0e1a0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/02b1be0d48924c327124732726097157-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/02f039058bd48307e6f653a2005c9dd2-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/03e0704b5690a2dee1861dc3ad3316c9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/03e7ef47cee6fa4ae7567394b99912b7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/04048aeca2c0f5d84639358008ed2ae7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/044a23cadb567653eb51d4eb40acaa88-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/051928341be67dcba03f0e04104d9047-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/05546b0e38ab9175cd905eebcc6ebb76-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/061412e4a03c02f9902576ec55ebbe77-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/07042ac7d03d3b9911a00da43ce0079a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/070dbb6024b5ef93784428afc71f2146-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/07211688a0869d995947a8fb11b215d6-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/072b030ba126b2f4b2374f342be9ed44-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/07563a3fe3bbe7e3ba84431ad9d055af-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/076023edc9187cf1ac1f1163470e479a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/0768281a05da9f27df178b5c39a51263-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/077e29b11be80ab57e1a2ecabb7da330-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/07811dc6c422334ce36a09ff5cd6fe71-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/08b255a5d42b89b0585260b6f2360bdd-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/08e6bea8e90ba87af3c9554d94db6579-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/09fb05dd477d4ae6479985ca56c5a12d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/0a0a0c8aaa00ade50f74a3f0ca981ed7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/0a5c79b1eaf15445da252ada718857e9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/0abdc563a06105aee3c6136871c9f4d1-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/0bed45bd5774ffddc95ffe500024f628-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/0c74b7f78409a4022a2c4c5a5ca3ee19-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/0d9095b0d6bbe98ea0c9c02b11b59ee3-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/0e55666a4ad822e0e34299df3591d979-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/0e7c7d6c41c76b9ee6445ae01cc0181d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/0ebcc77dc72360d0eb8e9504c78d38bd-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/0efbe98067c6c73dba1250d2beaa81f9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/0f3d014eead934bbdbacb62a01dc4831-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/1006ff12c465532f8c574aeaa4461b16-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/10c272d06794d3e5785d5e7c5356e9ff-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/10c66082c124f8afe3df4886f5e516e0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/10ce03a1ed01077e3e289f3e53c72813-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/1113d7a76ffceca1bb350bfe145467c6-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/1177967c7957072da3dc1db4ceb30e7a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/11b921ef080f7736089c757404650e40-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/1264a061d82a2edae1574b07249800d6-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/1271a7029c9df08643b631b02cf9e116-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/12a1d073d5ed3fa12169c67c4e2ce415-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/136f951362dab62e64eb8e841183c2a9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/13f3cf8c531952d72e5847c4183e6910-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/13fe9d84310e77f13a6d184dbf1232f3-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/147ebe637038ca50a1265abac8dea181-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/14e422f05b68cc0139988e128ee880df-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/14ea0d5b0cf49525d1866cb1e95ada5d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/165a59f7cf3b5c4396ba65953d679f17-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/1680e9fa7b4dd5d62ece800239bb53bd-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/16a5cdae362b8d27a1d8f8c7b78b4330-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/1700002963a49da13542e0726b7bb758-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/17d8da815fa21c57af9829fb0a869602-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/17ed8abedc255908be746d245e50263a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/17fafe5f6ce2f1904eb09d2e80a4cbf6-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/186a157b2992e7daed3677ce8e9fe40f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/18bb68e2b38e4a8ce7cf4f6b2625768c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/18d10dc6e666eab6de9215ae5b3d54df-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/192fc044e74dffea144f9ac5dc9f3395-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/1943102704f8f8f3302c2b730728e023-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/194cf6c2de8e00c05fcf16c498adc7bf-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/1abb1e1ea5f481b589da52303b091cbb-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/1b5230e3ea6d7123847ad55a1e06fffd-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/1baff70e2669e8376347efd3a874a341-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/1c303b0eed3133200cf715285011b4e4-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/1c54985e4f95b7819ca0357c0cb9a09f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/1ce927f875864094e3906a4a0b5ece68-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/1cecc7a77928ca8133fa24680a88d2f9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/1dba5eed8838571e1c80af145184e515-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/1f1baa5b8edac74eb4eaa329f14a0361-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/1f71e393b3809197ed66df836fe833e5-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/1ff8a7b5dc7a7d1f0ed65aaa29c04b1e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/20c86a628232a67e7bd46f76fba7ce12-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2131f8ecf18db66a758f718dc729e00e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/217e342fc01668b10cb1188d40d3370e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/21c5bba1dd6aed9ab48c2b34c1a0adde-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2227d753dc18505031869d44673728e2-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/227f6afd3b7f89b96c4bb91f95d50f6d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2288f691b58edecadcc9a8691762b4fd-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/22b1f2e0983160db6f7bb9f62f4dbb39-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/22fb0cee7e1f3bde58293de743871417-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/23af4b45f1e166141a790d1a3126e77a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2417dc8af8570f274e6775d4d60496da-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/24681928425f5a9133504de568f5f6df-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/24b43fb034a10d78bec71274033b4096-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/250cf8b51c773f3f8dc8b4be867a9a02-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/253614bbac999b38b5b60cae531c4969-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/253f7b5d921338af34da817c00f42753-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2612aa892d962d6f8056b195ca6e550d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2650d6089a6d640c5e85b2b88265dc2b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/269d837afada308dd4aeab28ca2d57e4-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/275d7fb2fd45098ad5c3ece2ed4a2824-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/27ed0fb950b856b06e1273989422e7d3-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/28dd2c7955ce926456240b2ff0100bde-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/291d43c696d8c3704cdbe0a72ade5f6c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/298f95e1bf9136124592c8d4825a06fc-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/299a23a2291e2126b91d54f3601ec162-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2aedcba61ca55ceb62d785c6b7f10a83-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2b0f658cbffd284984fb11d90254081f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2b24d495052a8ce66358eb576b8912c8-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2b45e8d6abf59038a975faeeb6dc0782-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2bb0502c80b7432eee4c5847a5fd077b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2bb232c0b13c774965ef8558f0fbd615-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2ca65f58e35d9ad45bf7f3ae5cfd08f1-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2cad8fa47bbef282badbb8de5374b894-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2cd4e8a2ce081c3d7c32c3cde4312ef7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2d1b2a5ff364606ff041650887723470-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2d2c8394e31101a261abf1784302bf75-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2d2ca7eedf739ef4c3800713ec482e1a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2e0aca891f2a8aedf265edf533a6d9a8-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2e1b24a664f5e9c18f407b2f9c73e821-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2eace51d8f796d04991c831a07059758-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2eb5657d37f474e4c4cf01e4882b8962-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2f2b265625d76a6704b08093c652fd79-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/2f37d10131f2a483a8dd005b3d14b0d9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/303ed4c69846ab36c2904d3ba8573050-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/30f8f6b940d1073d8b6a5eebc46dd6e5-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/312351bff07989769097660a56395065-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3210ddbeaa16948a702b6049b8d9a202-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3214a6d842cc69597f9edf26df552e43-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/325995af77a0e8b06d1204a171010b3a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/327708dd10d68b1361ad3addbaca01f2-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/32b3ee0272954b956a7d1f86f76afa21-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/32bb90e8976aab5298d5da10fe66f21d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/32cbf687880eb1674a07bf717761dd3a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/32fdab6559cdfa4f167f8c31b9199643-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/331316d4efb44682092a006307b9ae3a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3323fe11e9595c09af38fe67567a9394-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/333cb763facc6ce398ff83845f224d62-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/347665597cbfaef834886adbb848011f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/34ed066df378efacc9b924ec161e7639-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/350db081a661525235354dd3e19b8c05-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/351b33587c5fdd93bd42ef7ac9995a28-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/352fe25daf686bdb4edca223c921acea-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/353de26971b93af88da102641069b440-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/35464c848f410e55a13bb9d78e7fddd0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/35936504a37d53e03abdfbc7318d9ec7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/361440528766bbaaaa1901845cf4152b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3621f1454cacf995530ea53652ddf8fb-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/366f0bc7bd1d4bf414073cabbadfdfcd-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/36a1694bce9815b7e38a9dad05ad42e0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/36e729ec173b94133d8fa552e4029f8b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/37d097caf1299d9aa79c2c2b843d2d78-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/38811c5285e34e2e3319ab7d9f2cfa5b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/38913e1d6a7b94cb0f55994f679f5956-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/38db3aed920cf82ab059bfccbd02be6a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/38ed162a0dbef7b3fe0f628aa08b90e7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3937230de3c8041e4da6ac3246a888e8-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/393c55aea738548df743a186d15f3bef-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/39ae2ed11b14a4ccb41d35e9d1ba5d11-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/39d352b0395ba768e18f042c6e2a8621-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3a0844cee4fcf57de0c71e9ad3035478-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3a15c7d0bbe60300a39f76f8a5ba6896-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3a20f62a0af1aa152670bab3c602feed-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3a835d3215755c435ef4fe9965a3f2a0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3b3dbaf68507998acd6a5a5254ab2d76-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3baa271bc35fe054c86928f7016e8ae6-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3bf55bbad370a8fcad1d09b005e278c2-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3cfbdf468f0a03187f6cee51a25e5e9a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3d779cae2d46cf6a8a99a35ba4167977-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3dd48ab31d016ffcbf3314df2b3cb9ce-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3e60e09c222f206c725385f53d7e567c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3eb414bf1c2a66a09c185d60553417b8-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3f647cadf56541fb9513cb63ec370187-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3f998e713a6e02287c374fd26835d87e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3fab5890d8113d0b5a4178201dc842ad-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3fb451ca2e89b3a13095b059d8705b15-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3fc2c60b5782f641f76bcefc39fb2392-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/3fd60983292458bf7dee75f12d5e9e05-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/443dec3062d0286986e21dc0631734c9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4491777b1aa8b5b32c2e8666dbe1a495-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/44a2e0804995faf8d2e3b084a1e2db1d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/44ac09ac6a149136a4102ee4b4103ae6-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4500e4037738e13c0c18db508e18d483-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/453fadbd8a1a3af50a9df4df899537b5-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4558dbb6f6f8bb2e16d03b85bde76e2c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4588e674d3f0faf985047d4c3f13ed0d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/45fbc6d3e05ebd93369ce542e8f2322d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/464d828b85b0bed98e80ade0a5c43b0f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4671aeaf49c792689533b00664a5c3ef-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/46922a0880a8f11f8f69cbb52b1396be-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/46a558d97954d0692411c861cf78ef79-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/473447ac58e1cd7e96172575f48dca3b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/489d0396e6826eb0c1e611d82ca8b215-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/48ab2f9b45957ab574cf005eb8a76760-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/491442df5f88c6aa018e86dac21d3606-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/49182f81e6a13cf5eaa496d51fea6406-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/49ad23d1ec9fa4bd8d77d02681df5cfa-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/49b8b4f95f02e055801da3b4f58e28b7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4a2ddf148c5a9c42151a529e8cbdcc06-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4a8423d5e91fda00bb7e46540e2b0cf1-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4b21cf96d4cf612f239a6c322b10c8fe-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4b4edc2630fe75800ddc29a7b4070add-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4c56ff4ce4aaf9573aa5dff913df997a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4cb811134b9d39fc3104bd06ce75abad-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4da04049a062f5adfe81b67dd755cecc-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4db0f8b0fc895da263fd77fc8aecabe4-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4e0928de075538c593fbdabb0c5ef2c3-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4e2a6330465c8ffcaa696a5a16639176-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4e732ced3463d06de0ca9a15b6153677-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4e8412ad48562e3c9934f45c3e144d48-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4edaa105d5f53590338791951e38c3ad-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4fa177df22864518b2d7818d4db5db2d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/4fac9ba115140ac4f1c22da82aa0bc7f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/50905d7b2216bfeccb5b41016357176b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/50cf0763d8eb871776d4f28b39deb564-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/519c84155964659375821f7ca576f095-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/51e6d6e679953c6311757004d8cbbba9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/51ef186e18dc00c2d31982567235c559-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/5227b6aaf294f5f027273aebf16015f2-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/52292e0c763fd027c6eba6b8f494d2eb-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/5352696a9ca3397beb79f116f3a33991-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/54e36c5ff5f6a1802925ca009f3ebb68-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/556f391937dfd4398cbac35e050a2177-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/56584778d5a8ab88d6393cc4cd11e090-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/5737c6ec2e0716f3d8a7a5c4e0de0d9a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/57aeee35c98205091e18d1140e9f38cf-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/58191d2a914c6dae66371c9dcdc91b41-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/58238e9ae2dd305d79c2ebc8c1883422-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/58d4d1e7b1e97b258c9ed0b37e02d087-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/58e4d44e550d0f7ee0a23d6b02d9b0db-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/59b90e1005a220e2ebc542eb9d950b1e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/59dfa2df42d9e3d41f5b02bfc32229dd-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/5a142a55461d5fef016acfb927fee0bd-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/5abdf8b8520b71f3a528c7547ee92428-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/5b970a1d9be0fd100063fd6cd688b73e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/5d44ee6f2c3f71b73125876103c8f6c4-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/5d6646aad9bcc0be55b2c82f69750387-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/5dc126b503e374b0e08231344a7f493f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/5dd9db5e033da9c6fb5ba83c7a7ebea9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/5eac43aceba42c8757b54003a58277b5-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/5ef0b4eba35ab2d6180b0bca7e46b6f9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/5ef698cd9fe650923ea331c15af3b160-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/5f14615696649541a025d3d0f8e0447f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6048ff4e8cb07aa60b6777b6f7384d52-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/619205da514e83f869515c782a328d3c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/61b1fb3f59e28c67f3925f3c79be81a1-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/61b4a64be663682e8cb037d9719ad8cd-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6211080fa89981f66b1a0c9d55c61d0f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/62889e73828c756c961c5a6d6c01a463-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/62dad6e273d32235ae02b7d321578ee8-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/62f91ce9b820a491ee78c108636db089-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/632cee946db83e7a52ce5e8d6f0fed35-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/63538fe6ef330c13a05a3ed7e599d5f7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/635440afdfc39fe37995fed127d7df4f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/643de7cf7ba769c7466ccbc4adfd7fac-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6463c88460bd63bbe256e495c63aa40b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/64a08e5f1e6c39faeb90108c430eb120-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/654ad60ebd1ae29cedc37da04b6b0672-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/663772ea088360f95bac3dc7ffb841be-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6786f3c62fbf9021694f6e51cc07fe3c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/67c6a1e7ce56d3d6fa748ab6d9af3fd7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/67d16d00201083a2b118dd5128dd6f59-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/68053af2923e00204c3ca7c6a3150cf7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/68a9750337a418a86fe06c1991a1d64c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/69a5b5995110b36a9a347898d97a610e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/69d1fc78dbda242c43ad6590368912d4-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/69dafe8b58066478aea48f3d0f384820-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6a2feef8ed6a9fe76d6b3f30f02150b4-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6a508a60aa3bf9510ea6acb021c94b48-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6aca97005c68f1206823815f66102863-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6ad4174eba19ecb5fed17411a34ff5e6-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6aed000af86a084f9cb0264161e29dd3-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6c1da886822c67822bcf3679d04369fa-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6c340f25839e6acdc73414517203f5f0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6c349155b122aa8ad5c877007e05f24f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6c3cf77d52820cd0fe646d38bc2145ca-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6c524f9d5d7027454a783c841250ba71-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6c9882bbac1c7093bd25041881277658-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6d0f846348a856321729a2f36734d1a7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6d9cb7de5e8ac30bd5e8734bc96a35c1-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6e2713a6efee97bacb63e52c54f0ada0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6e5025ccc7d638ae4e724da8938450a6-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6ef80bb237adf4b6f77d0700e1255907-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6f1d0705c91c2145201df18a1a0c7345-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6f2268bd1d3d3ebaabb04d6b5d099425-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6fab6e3aa34248ec1e34a4aeedecddc8-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/6fe131632103526e3a6e8114c78eb1e1-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/70222949cc0db89ab32c9969754d4758-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/70efdf2ec9b086079795c442636b55fb-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7137debd45ae4d0ab9aa953017286b20-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/71887f62f073a78511cbac56f8cab53f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/71ad16ad2c4d81f348082ff6c4b20768-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/72b386224056bf940cd5b01341f65e9d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7371364b3d72ac9a3ed8638e6f0be2c9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/73e5080f0f3804cb9cf470a8ce895dac-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/73fed7fd472e502d8908794430511f4d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/74071a673307ca7459bcf75fbd024e09-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/743394beff4b1282ba735e5e3723ed74-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7486cef2522ee03547cfb970a404a874-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/748ba69d3e8d1af87f84fee909eef339-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/752d25a1f8dbfb2d656bac3094bfb81c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/758a06618c69880a6cee5314ee42d52f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/75fc093c0ee742f6dddaa13fff98f104-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7634ea65a4e6d9041cfd3f7de18e334a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/766ebcd59621e305170616ba3d3dac32-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/769675d7c11f336ae6573e7e533570ec-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7876acb66640bad41f1e1371ef30c180-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7884a9652e94555c70f96b6be63be216-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/788d986905533aba051261497ecffcbb-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/79514e888b8f2acacc68738d0cbb803e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7993e11204b215b27694b6f139e34ce8-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7a006957be65e608e863301eb98e1808-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7a6a74cbe87bc60030a4bd041dd47b78-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7a98af17e63a0ac09ce2e96d03992fbc-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7b13b2203029ed80337f27127a9f1d28-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7b7a53e239400a13bd6be6c91c4f6c4e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7bccfde7714a1ebadf06c5f4cea752c1-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7c82fab8c8f89124e2ce92984e04fb40-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7cbbc409ec990f19c78c75bd1e06f215-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7cc234202e98d2722580858573fd0817-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7cce53cf90577442771720a370c3c723-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7e0a0209b929d097bd3e8ef30567a5c1-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7e3b7a5bafcb0fa8e8dfe3ea6aca9186-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7e7757b1e12abcb736ab9a754ffb617a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7e7e69ea3384874304911625ac34321c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7edccc661418aeb5761dbcdc06ad490c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7f018eb7b301a66658931cb8a93fd6e8-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7fe1f8abaad094e0b5cb1b01d712f708-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/7fea637fd6d02b8f0adf6f7dc36aed93-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/812b4ba287f5ee0bc9d43bbf5bbe87fb-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/819f46e52c25763a55cc642422644317-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/81b3833e2504647f9d794f7d7b9bf341-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/81c650caac28cdefce4de5ddc18befa0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/81ca0262c82e712e50c580c032d99b60-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/81e5f81db77c596492e6f1a5a792ed53-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8208974663db80265e9bfe7b222dcb18-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/82161242827b703e6acf9c726942a1e4-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/821fa74b50ba3f7cba1e6c53e8fa6845-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/82b8a3434904411a9fdc43ca87cee70c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/831caa1b600f852b7844499430ecac17-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/838e8afb1ca34354ac209f53d90c3a43-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/83f97f4825290be4cb794ec6a234595f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8420d359404024567b5aefda1231af24-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/84438b7aae55a0638073ef798e50b4ef-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/84b20b1f5a0d103f5710bb67a043cd78-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/84c6494d30851c63a55cdb8cb047fadd-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/84ddfb34126fc3a48ee38d7044e87276-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/850af92f8d9903e7a4e0559a98ecc857-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/851300ee84c2b80ed40f51ed26d866fc-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8597a6cfa74defcbde3047c891d78f90-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/861dc9bd7f4e7dd3cccd534d0ae2a2e9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/86a1793f65aeef4aeef4b479fc9b2bca-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/86b122d4358357d834a87ce618a55de0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/86df7dcfd896fcaf2674f757a2463eba-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/86e78499eeb33fb9cac16b7555b50767-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/883e881bb4d22a7add958f2d6b052c9f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/884d79963bd8bc0ae9b13a1aa71add73-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8929c70f8d710e412d38da624b21c3c8-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/892c3b1c6dccd52936e27cbd0ff683d6-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/892c91e0a653ba19df81a90f89d99bcd-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/89d4402dc03d3b7318bbac10203034ab-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/89f0fd5c927d466d6ec9a21b9ac34ffa-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/89fcd07f20b6785b92134bd6c1d0fa42-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8a1d694707eb0fefe65871369074926d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8b5040a8a5baf3e0e67386c2e3a9b903-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8b8388180314a337c9aa3c5aa8e2f37a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8bb88f80d334b1869781beb89f7b73be-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8c249675aea6c3cbd91661bbae767ff1-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8ca8da41fe1ebc8d3ca31dc14f5fc56c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8cb22bdd0b7ba1ab13d742e22eed8da2-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8cbd005a556ccd4211ce43f309bc0eac-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8ce6790cc6a94e65f17f908f462fae85-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8d3bba7425e7c98c50f52ca1b52d3735-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8d420fa35754d1f1c19969c88780314d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8e68c3c7bf14ad0bcaba52babfa470bd-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8edd72158ccd2a879f79cb2538568fdc-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8fb5f8be2aa9d6c64a04e3ab9f63feee-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/8fecb20817b3847419bb3de39a609afe-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/900c563bfd2c48c16701acca83ad858a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/90599c8fdd2f6e7a03ad173e2f535751-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/907edb0aa6986220dbffb79a788596ee-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/908c9a564a86426585b29f5335b619bc-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/9185f3ec501c674c7c788464a36e7fb3-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/92a0e7a415d64ebafcb16a8ca817cde4-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/92af93f73faf3cefc129b6bc55a748a9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/934815ad542a4a7c5e8a2dfa04fea9f5-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/94b5bde6de888ddf9cde6748ad2523d1-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/95f8d9901ca8878e291552f001f67692-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/96671501524948bc3937b4b30d0e57b9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/97416ac0f58056947e2eb5d5d253d4f2-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/976abf49974d4686f87192efa0513ae0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/978fce5bcc4eccc88ad48ce3914124a2-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/979d472a84804b9f647bc185a877a8b5-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/97d98119037c5b8a9663cb21fb8ebf47-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/98b17f068d5d9b7668e19fb8ae470841-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/98dce83da57b0395e163467c9dae521b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/995665640dc319973d3173a74a03860c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/99adff456950dd9629a5260c4de21858-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/99c5e07b4d5de9d18c350cdf64c5aa3d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/9a1756fd0c741126d7bbd4b692ccbd91-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/9a3d458322d70046f63dfd8b0153ece4-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/9a49a25d845a483fae4be7e341368e36-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/9aa42b31882ec039965f3c4923ce901b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/9c838d2e45b2ad1094d42f4ef36764f6-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/9c8661befae6dbcd08304dbf4dcaf0db-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/9cb9ed4f35cf7c2f295cc2bc6f732a84-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/9cf81d8026a9018052c429cc4e56739b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/9d7311ba459f9e45ed746755a32dcd11-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/9ddb9dd5d8aee9a76bf217a2a3c54833-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/9e82757e9a1c12cb710ad680db11f6f1-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/9ef2ed4b7fd2c810847ffa5fa85bce38-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/9f44e956e3a2b7b5598c625fcc802c36-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/9f53d83ec0691550f7d2507d57f4f5a2-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a00e5eb0973d24649a4a920fc53d9564-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a0160709701140704575d499c997b6ca-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a03fa30821986dff10fc66647c84c9c3-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a081cab429ff7a3b96e0a07319f1049e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a1d7311f2a312426d710e1c617fcbc8c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a2186aa7c086b46ad4e8bf81e2a3a19b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a34bacf839b923770b2c360eefa26748-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a36e841c5230a79c2102036d2e259848-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a4666cd9e1ab0e4abf05a0fb232f4ad3-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a48564053b3c7b54800246348c7fa4a0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a49e9411d64ff53eccfdd09ad10a15b3-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a50abba8132a77191791390c3eb19fe7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a51fb975227d6640e4fe47854476d133-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a5e0ff62be0b08456fc7f1e88812af3d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a6d259bfbfa2062843ef543e21d7ec8e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a6db4ed04f1621a119799fd3d7545d3d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a6ea8471c120fe8cc35a2954c9b9c595-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a74c3bae3e13616104c1b25f9da1f11f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a78482ce76496fcf49085f2190e675b4-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a7a3d70c6d17a73140918996d03c014f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a82d922b133be19c1171534e6594f754-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a8345c3bb9e3896ea538ce77ffaf2c20-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a869ccbcbd9568808b8497e28275c7c8-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a8abb4bb284b5b27aa7cb790dc20f80b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a8baa56554f96369ab93e4f3bb068c22-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a8e864d04c95572d1aece099af852d0a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a8ecbabae151abacba7dbde04f761c37-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a96b65a721e561e1e3de768ac819ffbb-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/a9813e9550fee3110373c21fa012eee7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ab452534c5ce28c4fbb0e102d4a4fb2e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ab541d874c7bc19ab77642849e02b89f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ab7314887865c4265e896c6e209d1cd6-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/acab0116c354964a558e65bdd07ff047-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ad71c82b22f4f65b9398f76d8be4c615-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ad972f10e0800b49d76fed33a21f6698-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/addfa9b7e234254d26e9c7f2af1005cb-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ade55409d1224074754035a5a937d2e0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ae5e3ce40e0404a45ecacaaf05e5f735-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/aebf7782a3d445f43cf30ee2c0d84dee-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b0169350cd35566c47ba83c6ec1d6f82-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b030afbb3a8af8fb0759241c97466ee4-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b069b3415151fa7217e870017374de7c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b06f50d1f89bd8b2a0fb771c1a69c2b0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b166b57d195370cd41f80dd29ed523d9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b19aa25ff58940d974234b48391b9549-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b1a59b315fc9a3002ce38bbe070ec3f5-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b22b257ad0519d4500539da3c8bcf4dd-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b24d516bb65a5a58079f0f3526c87c57-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b2531e7bb29bf22e1daae486fae3417a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b299ad862b6f12cb57679f0538eca514-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b2ab001909a8a6f04b51920306046ce5-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b2eeb7362ef83deff5c7813a67e14f0a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b3b43aeeacb258365cc69cdaf42a68af-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b3b4d2dbedc99fe843fd3dedb02f086f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b432f34c5a997c8e7c806a895ecc5e25-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b4d168b48157c623fbd095b4a565b5bb-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b55ec28c52d5f6205684a473a2193564-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b60c5ab647a27045b462934977ccad9a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b6617980ce90f637e68c3ebe8b9be745-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b6e710870acb098e584277457ba89d68-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b75bd27b5a48a1b48987a18d831f6336-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b7fede84c2be02ccb9c77107956560eb-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b87470782489389f344c4fa4ceb5260c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/b8b9c74ac526fffbeb2d39ab038d1cd7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ba3866600c3540f67c1e9575e213be0a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/bbeb0c1b1fd44e392c7ce2fdbd137e87-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/bc4e356fee1972242c8f7eabf4dff517-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/bd0cc810b580b35884bd9df37c0e8b0f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/bd686fd640be98efaae0091fa301e613-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/bdc4626aa1d1df8e14d80d345b2a442d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/bea5955b308361a1b07bc55042e25e54-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/bf201d5407a6509fa536afc4b380577e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/bf424cb7b0dea050a42b9739eb261a3a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/bf62768ca46b6c3b5bea9515d1a1fc45-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/bf8229696f7a3bb4700cfddef19fa23f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c02f9de3c2f3040751818aacc7f60b74-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c0e90532fb42ac6de18e25e95db73047-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c182f930a06317057d31c73bb2fedd4f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c1fea270c48e8079d8ddf7d06d26ab52-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c22abfa379f38b5b0411bc11fa9bf92f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c24cd76e1ce41366a4bbe8a49b02a028-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c2964caac096f26db222cb325aa267cb-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c2ba1bc54b239208cb37b901c0d3b363-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c2f32522a84d5e6357e6abac087f1b0b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c30fb4dc55d801fc7473840b5b161dfa-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c32d9bf27a3da7ec8163957080c8628e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c3535febaff29fcb7c0d20cbe94391c7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c366c2c97d47b02b24c3ecade4c40a01-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c3a690be93aa602ee2dc0ccab5b7b67e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c44e503833b64e9f27197a484f4257c0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c4b31ce7d95c75ca70d50c19aef08bf1-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c4de8ced6214345614d33fb0b16a8acd-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c54e7837e0cd0ced286cb5995327d1ab-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c57168a952f5d46724cf35dfc3d48a7f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c59b469d724f7919b7d35514184fdc0f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c5a4e7e6882845ea7bb4d9462868219b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c5dc3e08849bec07e33ca353de62ea04-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c6036a69be21cb660499b75718a3ef24-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c61f571dbd2fb949d3fe5ae1608dd48b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c65d7bd70fe3e5e3a2f3de681edc193d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c7558e9d1f956b016d1fdba7ea132378-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c75b6f114c23a4d7ea11331e7c00e73c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c850371fda6892fbfd1c5a5b457e5777-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c86a7ee3d8ef0b551ed58e354a836f2b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c8862fc1a32725712838863fb1a260b9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c902b497eb972281fb5b4e206db38ee6-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/c930eecd01935feef55942cc445f708f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ca3ec598002d2e7662e2ef4bdd58278b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/cb8acb1dc9821bf74e6ca9068032d623-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/cb8da6767461f2812ae4290eac7cbc42-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/cbcb58ac2e496207586df2854b17995f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ccbd8ca962b80445df1f7f38c57759f0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/cd3afef9b8b89558cd56638c3631868a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/cdd96eedd7f695f4d61802f8105ba2b0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ce5140df15d046a66883807d18d0264b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ced556cd9f9c0c8315cfbe0744a3baf0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/cedebb6e872f539bef8c3f919874e9d7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/cf2226ddd41b1a2d0ae51dab54d32c36-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/cfee398643cbc3dc5eefc89334cacdc1-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/d0010a6f34908640a4a6da2389772a78-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/d10ec7c16cbe9de8fbb1c42787c3ec26-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/d1e946f4e67db4b362ad23818a6fb78a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/d2cd33e9c0236a8c2d8bd3fa91ad3acf-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/d2ddea18f00665ce8623e36bd4e3c7c5-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/d38901788c533e8286cb6400b40b386d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/d3a7f48c12e697d50c8a7ae7684644ef-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/d3d80b656929a5bc0fa34381bf42fbdd-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/d494020ff8ec181ef98ed97ac3f25453-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/d54ce9de9df77c579775a7b6b1a4bdc0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/d594b1a945b5d645e59e21f88bd2d83b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/d5e2c0adad503c91f91df240d0cd4e49-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/d7a84628c025d30f7b2c52c958767e76-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/d8bf84be3800d12f74d8b05e9b89836f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/d8d31bd778da8bdd536187c36e48892b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/d8e1344e27a5b08cdfd5d027d9b8d6de-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/d9896106ca98d3d05b8cbdf4fd8b13a1-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/d9fc0cdb67638d50f411432d0d41d0ba-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/d9ff90f4000eacd3a6c9cb27f78994cf-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/da0d1111d2dc5d489242e60ebcbaf988-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/dab49080d80c724aad5ebf158d63df41-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/db5cea26ca37aa09e5365f3e7f5dd9eb-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/db85e2590b6109813dafa101ceb2faeb-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/db98dc0dbafde48e8f74c0de001d35e4-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/dbb422937d7ff56e049d61da730b3e11-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/dbd22ba3bd0df8f385bdac3e9f8be207-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/dc6a6489640ca02b0d42dabeb8e46bb7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/dc6a7e655d7e5840e66733e9ee67cc69-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/dc960c46c38bd16e953d97cdeefdbc68-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/dcda54e29207294d8e7e1b537338b1c0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/dcf6070a4ab7f3afbfd2809173e0824b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/dd8eb9f23fbd362da0e3f4e70b878c16-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ddcbe25988981920c872c1787382f04d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/dea9ddb25cbf2352cf4dec30222a02a5-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/deb54ffb41e085fd7f69a75b6359c989-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/df0aab058ce179e4f7ab135ed4e641a9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/df1f1d20ee86704251795841e6a9405a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/dfce06801e1a85d6d06f1fdd4475dacd-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/dfd7468ac613286cdbb40872c8ef3b06-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/dfeb9598fbfb97cc6bbcc0aff2c785d6-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e00406144c1e7e35240afed70f34166a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e0126439e08ddfbdf4faa952dc910590-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e034fb6b66aacc1d48f445ddfb08da98-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e0688d13958a19e087e123148555e4b4-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e077e1a544eec4f0307cf5c3c721d944-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e0a209539d1e74ab9fe46b9e01a19a97-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e0ab531ec312161511493b002f9be2ee-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e0f7a4d0ef9b84b83b693bbf3feb8e6e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e11943a6031a0e6114ae69c257617980-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e139c454239bfde741e893edb46a06cc-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e19347e1c3ca0c0b97de5fb3b690855a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e1e32e235eee1f970470a3a6658dfdd5-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e22312179bf43e61576081a2f250f845-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e3408432c1a48a52fb6c74d926b38886-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e369853df766fa44e1ed0ff613f563bd-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e449b9317dad920c0dd5ad0a2a2d5e49-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e4a93f0332b2519177ed55741ea4e5e7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e5f6ad6ce374177eef023bf5d0c018b6-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e60e81c4cbe5171cd654662d9887aec2-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e6384711491713d29bc63fc5eeb5ba4f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e655c7716a4b3ea67f48c6322fc42ed6-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e6acf4b0f69f6f6e60e9a815938aa1ff-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e6af401c28c1790eaef7d55c92ab6ab6-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e6ba70fc093b4ce912d769ede1ceeba8-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e6c2dc3dee4a51dcec3a876aa2339a78-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e6cbc650cd5798a05dfd0f51d14cde5c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e6d8545daa42d5ced125a4bf747b3688-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e702e51da2c0f5be4dd354bb3e295d37-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e71e5cd119bbc5797164fb0cd7fd94a4-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e7b24b112a44fdd9ee93bdf998c6ca0e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e7e23670481ac78b3c4122a99ba60573-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e8bf0f27d70d480d3ab793bb7619aaa5-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e91068fff3d7fa1594dfdf3b4308433a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e93028bdc1aacdfb3687181f2031765d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e9412ee564384b987d086df32d4ce6b7-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e94f63f579e05cb49c05c2d050ead9c0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e94fe9ac8dc10dd8b9a239e6abee2848-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e97ee2054defb209c35fe4dc94599061-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/e9fb2eda3d9c55a0d89c98d6c54b5b3e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ea159dc9788ffac311592613b7f71fbb-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ea204361fe7f024b130143eb3e189a18-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ea6b2efbdd4255a9f1b3bbc6399b58f4-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ea8fcd92d59581717e06eb187f10666d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ebd6d2f5d60ff9afaeda1a81fc53e2d0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/eddb904a6db773755d2857aacadb1cb0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ede7e2b6d13a41ddf9f4bdef84fdc737-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ef0d3930a7b6c95bd2b32ed45989c61f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ef72d53990bc4805684c9b61fa64a102-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/efdf562ce2fb0ad460fd8e9d33e57f57-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f016e59c7ad8b1d72903bb1aa5720d53-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f0204e1d3ee3e4b05de4e2ddbd39e076-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f0935e4cd5920aa6c7c996a5ee53a70f-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f0f6ba4b5e0000340312d33c212c3ae8-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f12ee9734e1edf70ed02d9829018b3d9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f1981e4bd8a0d6d8462016d2fc6276b3-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f22e4747da1aa27e363d86d40ff442fe-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f231f2107df69eab0a3862d50018a9b2-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f24ad6f72d6cc4cb51464f2b29ab69d3-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f26dab9bf6a137c3b6782e562794c2f2-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f2fc990265c712c49d51a18a32b39f0c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f31b20466ae89669f9741e047487eb37-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f337d999d9ad116a7b4f3d409fcc6480-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f44ee263952e65b3610b8ba51229d1f9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f4552671f8909587cf485ea990207f3b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f457c545a9ded88f18ecee47145a72c0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f45a1078feb35de77d26b3f7a52ef502-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f4b9ec30ad9f68f89b29639786cb62ef-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f507783927f2ec2737ba40afbd17efb5-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f55cadb97eaff2ba1980e001b0bd9842-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f5f8590cd58a54e94377e6ae2eded4d9-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f60bb6bb4c96d4df93c51bd69dcc15a0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f61d6947467ccd3aa5af24db320235dd-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f69e505b08403ad2298b9f262659929a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f708f064faaf32a43e4d3c784e6af9ea-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f75526659f31040afeb61cb7133e4e6d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f79921bbae40a577928b76d2fc3edc2a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f7e0b956540676a129760a3eae309294-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f80bf05527157a8c2a7bb63b22f49aaa-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f80ff32e08a25270b5f252ce39522f72-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f87522788a2be2d171666752f97ddebb-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f8da71e562ff44a2bc7edf3578c593da-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f9be311e65d81a9ad8150a60844bb94c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/f9d1152547c0bde01830b7e8bd60024c-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/fa7cdfad1a5aaf8370ebeda47a1ff1c3-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/fa84632d742f2729dc32ce8cb5d49733-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/faafda66202d234463057972460c04f5-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/facf9f743b083008a894eee7baa16469-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/fb2606a5068901da92473666256e6e5b-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/fb3f76858cb38e5b7fd113e0bc1c0721-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/fb60d411a5c5b72b2e7d3527cfc84fd0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/fb89fd138b104dcf8e2077ad2a23954d-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/fc79250f8c5b804390e8da280b4cf06e-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/fca0789e7891cbc0583298a238316122-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/fcdf25d6e191893e705819b177cddea0-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/fd69dbe29f156a7ef876a40a94f65599-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/fe2d010308a6b3799a3d9c728ee74244-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/fec8d47d412bcbeece3d9128ae855a7a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/fed33392d3a48aa149a87a38b875ba4a-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ffbd6cbb019a1413183c8d08f2929307-Abstract.html', 'https://papers.nips.cc//paper/2017/hash/ffeabd223de0d4eacb9a3e6e53e5448d-Abstract.html']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D6iRtOAO7_bK",
        "outputId": "95eda45c-f5b2-44b3-de3e-6293b983ef98"
      },
      "source": [
        "for url in papers_url:\n",
        "  r=requests.get(url)\n",
        "  htmlContent=r.content\n",
        "  soup= BeautifulSoup(htmlContent,'lxml')\n",
        "  abstracts=[]\n",
        "  abstract=[]\n",
        "  count=1\n",
        "  for i in soup('div',class_='col',)and soup.find_all('p'):\n",
        "    abstract.append(i.text)\n",
        "    if len(abstract)>2:\n",
        "      print(abstract[2])\n",
        "      count+=1\n",
        "      print(count)\n",
        "      abstracts.append(abstract[2])\n",
        "      abstract.clear\n",
        "print(abstracts)\n",
        "print(count)\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2\n",
            "\n",
            "3\n",
            "This paper deals with the unsupervised domain adaptation problem, where one wants to estimate a prediction function $f$ in a given target domain without any labeled sample by exploiting the knowledge available from a source domain where labels are known. Our work makes the following assumption: there exists a  non-linear transformation between the joint feature/label space distributions of the two domain $\\ps$ and $\\pt$. We propose a solution of this problem with optimal transport, that allows to recover an estimated target $\\pt^f=(X,f(X))$ by optimizing simultaneously the optimal coupling and $f$. We show that our method corresponds to the minimization of a bound on the target error, and provide an efficient algorithmic solution, for which convergence is proved. The versatility of our approach, both in terms of class of hypothesis or loss functions is demonstrated with real world classification and regression problems, for which we reach or surpass state-of-the-art results.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "Affine policies (or control) are widely used as a solution approach in dynamic optimization where computing an optimal adjustable solution is usually intractable. While the worst case performance of affine policies can be significantly bad, the empirical performance is observed to be near-optimal for a large class of problem instances. For instance, in the two-stage dynamic robust optimization problem with linear covering constraints and uncertain right hand side, the worst-case approximation bound for affine policies is $O(\\sqrt m)$ that is also tight (see Bertsimas and Goyal (2012)), whereas observed empirical performance is near-optimal. In this paper, we aim to address this stark-contrast between the worst-case and the empirical performance of affine policies. In particular, we  show that affine policies give a good approximation for the two-stage adjustable robust optimization problem with high probability on random instances where the constraint coefficients are generated i.i.d. from a large class of distributions; thereby, providing a theoretical justification of the observed empirical performance. On the other hand, we also present a distribution such that the performance bound for affine policies on instances generated according to that distribution is $\\Omega(\\sqrt m)$ with high probability; however, the constraint coefficients are not i.i.d.. This demonstrates that the empirical performance of affine policies can depend on the generative model for instances.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "We consider the problem of non-parametric Conditional Independence testing (CI testing) for continuous random variables. Given i.i.d samples from the joint distribution $f(x,y,z)$ of continuous random vectors $X,Y$ and $Z,$ we determine whether $X \\independent Y \\vert Z$. We approach this by converting the conditional independence test into a classification problem.  This allows us to harness very powerful classifiers like gradient-boosted trees and deep neural networks.  These models can handle complex probability distributions and allow us to perform significantly better compared to the prior state of the art, for high-dimensional CI testing. The main technical challenge in the classification problem is the need for samples from the conditional product distribution $f^{CI}(x,y,z) = f(x|z)f(y|z)f(z)$ -- the joint distribution if and only if $X \\independent Y \\vert Z.$ -- when given access only to i.i.d.  samples from the true joint distribution $f(x,y,z)$.  To tackle this problem we propose a novel nearest neighbor bootstrap procedure and theoretically show that our generated samples are indeed close to $f^{CI}$ in terms of total variational distance. We then develop theoretical results regarding the generalization bounds for classification for our problem, which translate into error bounds for CI testing. We provide a novel analysis of Rademacher type classification bounds in the presence of non-i.i.d \\textit{near-independent} samples. We empirically validate the performance of our algorithm on simulated and real datasets and show performance gains over previous methods.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "Suppose, we are given a set of $n$ elements to be clustered into $k$ (unknown) clusters, and an oracle/expert labeler that can interactively answer pair-wise queries of the form, ``do two elements $u$ and $v$ belong to the same cluster?''. The goal is to recover the optimum clustering by asking the minimum number of queries. In this paper, we provide a rigorous theoretical study of this basic problem of query complexity of interactive clustering, and give strong information theoretic lower bounds, as well as nearly matching upper bounds. Most clustering problems come with a similarity matrix, which is used by an automated process to cluster similar points together. To improve accuracy of clustering, a fruitful approach in recent years has been to ask a domain expert or crowd to obtain labeled data interactively. Many heuristics have been proposed, and all of these use a similarity function to come up with a querying strategy. Even so, there is a lack systematic theoretical study. Our main contribution in this paper is to show the dramatic power of side information aka similarity matrix on reducing the query complexity of clustering. A similarity matrix represents noisy pair-wise relationships such as one computed by some  function on attributes of the elements. A natural noisy model is where similarity values are drawn independently from some arbitrary probability distribution $f_+$ when the underlying pair of elements belong to the same cluster, and from some $f_-$ otherwise. We show that given such a similarity matrix, the query complexity reduces drastically from $\\Theta(nk)$ (no similarity matrix) to $O(\\frac{k^2\\log{n}}{\\cH^2(f_+\\|f_-)})$ where $\\cH^2$ denotes the squared Hellinger divergence. Moreover, this is also information-theoretic optimal within an $O(\\log{n})$ factor. Our algorithms are all efficient, and parameter free, i.e., they work without any knowledge of $k, f_+$ and $f_-$, and only depend logarithmically with $n$.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "Kernel methods provide a principled way to perform non linear, nonparametric learning. They rely on solid functional analytic foundations and enjoy optimal statistical properties. However, at least in their basic form,  they have limited  applicability in large scale scenarios because of stringent computational requirements  in terms of time and especially memory. In this paper, we take a substantial step in scaling up kernel methods, proposing FALKON, a novel algorithm that allows to efficiently process millions of points. FALKON is derived combining several algorithmic principles, namely stochastic subsampling, iterative solvers and preconditioning. Our theoretical analysis shows that  optimal statistical accuracy  is achieved  requiring essentially $O(n)$ memory and $O(n\\sqrt{n})$  time. An extensive experimental analysis on large scale datasets shows that, even with a single machine,  FALKON   outperforms  previous state of the art solutions, which exploit parallel/distributed architectures.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "The inverse covariance matrix provides considerable insight for understanding statistical models in the multivariate setting.  In particular, when the distribution over variables is assumed to be multivariate normal, the sparsity pattern in the inverse covariance matrix, commonly referred to as the precision matrix, corresponds to the adjacency matrix representation of the Gauss-Markov graph, which encodes conditional independence statements between variables.  Minimax results under the spectral norm have previously been established for covariance matrices, both sparse and banded, and for sparse precision matrices.  We establish minimax estimation bounds for estimating banded precision matrices under the spectral norm. Our results greatly improve upon the existing bounds; in particular, we find that the minimax rate for estimating banded precision matrices matches that of estimating banded covariance matrices.  The key insight in our analysis is that we are able to obtain barely-noisy estimates of $k \\times k$ subblocks of the precision matrix by inverting slightly wider blocks of the empirical covariance matrix along the diagonal.  Our theoretical results are complemented by experiments demonstrating the sharpness of our bounds.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "We consider the problem of repeated bidding in online advertising auctions when some side information (e.g. browser cookies) is available ahead of submitting a bid in the form of a $d$-dimensional vector. The goal for the advertiser is to maximize the total utility (e.g. the total number of clicks) derived from displaying ads given that a limited budget $B$ is allocated for a given time horizon $T$. Optimizing the bids is modeled as a contextual Multi-Armed Bandit (MAB) problem with a knapsack constraint and a continuum of arms. We develop UCB-type algorithms that combine two streams of literature: the confidence-set approach to linear contextual MABs and the probabilistic bisection search method for stochastic root-finding. Under mild assumptions on the underlying unknown distribution, we establish distribution-independent regret bounds of order $\\tilde{O}(d \\cdot \\sqrt{T})$ when either $B = \\infty$ or when $B$ scales linearly with $T$.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "Neural network configurations with random weights play an important role in the analysis of deep learning. They define the initial loss landscape and are closely related to kernel and random feature methods. Despite the fact that these networks are built out of random matrices, the vast and powerful machinery of random matrix theory has so far found limited success in studying them. A main obstacle in this direction is that neural networks are nonlinear, which prevents the straightforward utilization of many of the existing mathematical results. In this work, we open the door for direct applications of random matrix theory to deep learning by demonstrating that the pointwise nonlinearities typically applied in neural networks can be incorporated into a standard method of proof in random matrix theory known as the moments method. The test case for our study is the Gram matrix $Y^TY$, $Y=f(WX)$, where $W$ is a random weight matrix, $X$ is a random data matrix, and $f$ is a pointwise nonlinear activation function. We derive an explicit representation for the trace of the resolvent of this matrix, which defines its limiting spectral distribution. We apply these results to the computation of the asymptotic performance of single-layer random feature methods on a memorization task and to the analysis of the eigenvalues of the data covariance matrix as it propagates through a neural network. As a byproduct of our analysis, we identify an intriguing new class of activation functions with favorable properties.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "We consider robust optimization problems, where the goal is to optimize in the worst case over a class of objective functions. We develop a reduction from robust improper optimization to stochastic optimization: given an oracle that returns $\\alpha$-approximate solutions for distributions over objectives, we compute a distribution over solutions that is $\\alpha$-approximate in the worst case.  We show that derandomizing this solution is NP-hard in general, but can be done for a broad class of statistical learning tasks.  We apply our results to robust neural network training and submodular optimization.  We evaluate our approach experimentally on corrupted character classification and robust influence maximization in networks.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "A problem that has been of recent interest in statistical inference, machine learning and signal processing is that of understanding the asymptotic behavior of regularized least squares solutions under random measurement matrices (or dictionaries). The Least Absolute Shrinkage and Selection Operator (LASSO or least-squares with $\\ell_1$ regularization) is perhaps one of the most interesting examples. Precise expressions for the asymptotic performance of LASSO have been obtained for a number of different cases, in particular when the elements of the dictionary matrix are sampled independently from a Gaussian distribution. It has also been empirically observed that the resulting expressions remain valid when the entries of the dictionary matrix are independently sampled from certain non-Gaussian distributions. In this paper, we confirm these observations theoretically when the distribution is sub-Gaussian. We further generalize the previous expressions for a broader family of regularization functions and under milder conditions on the underlying random, possibly non-Gaussian, dictionary matrix. In particular, we establish the universality of the asymptotic statistics (e.g., the average quadratic risk) of LASSO with non-Gaussian dictionaries.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "Source coding is the canonical problem of data compression in information theory. In a  locally encodable source coding, each compressed bit depends on only few bits of the input. In this paper, we show that a recently popular model of semisupervised clustering is equivalent to locally encodable source coding. In this model, the task is to perform multiclass labeling of unlabeled elements. At the beginning, we can ask in parallel a set of simple queries to an oracle who provides (possibly erroneous) binary answers  to the queries. The queries cannot involve more than two (or a fixed constant number $\\Delta$ of) elements. Now the labeling of all the elements (or clustering) must be performed based on the (noisy) query answers. The goal is to recover all the correct labelings while minimizing the number of such queries. The equivalence to locally encodable source codes leads us to find  lower bounds on the number of queries required in variety of scenarios. We are also able to show fundamental limitations of pairwise `same cluster' queries - and propose pairwise AND queries, that provably performs better in many situations.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "We study the online learning problem of a bidder who participates in repeated auctions. With the goal of maximizing his T-period payoff, the bidder determines the optimal allocation of his budget among his bids for $K$ goods at each period. As a bidding strategy, we propose a polynomial-time algorithm, inspired by the dynamic programming approach to the knapsack problem. The proposed algorithm, referred to as dynamic programming on discrete set (DPDS), achieves a regret order of $O(\\sqrt{T\\log{T}})$. By showing that the regret is lower bounded by $\\Omega(\\sqrt{T})$ for any strategy, we conclude that DPDS is order optimal up to a $\\sqrt{\\log{T}}$ term. We evaluate the performance of DPDS empirically in the context of virtual trading in wholesale electricity markets by using historical data from the New York market. Empirical results show that DPDS consistently outperforms benchmark heuristic methods that are derived from machine learning and online learning approaches.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "In this paper, we study the problem of maximizing continuous submodular functions that naturally arise in many learning applications such as those involving utility functions in active learning and sensing, matrix approximations and network inference. Despite the apparent lack of convexity in such functions, we prove that stochastic projected gradient methods can provide strong approximation guarantees for maximizing continuous submodular functions with convex constraints. More specifically, we prove that for monotone continuous DR-submodular functions, all fixed points of projected gradient ascent provide a factor $1/2$ approximation to the global maxima. We also study stochastic gradient methods and show that after $\\mathcal{O}(1/\\epsilon^2)$ iterations these methods reach solutions which achieve in expectation objective values exceeding $(\\frac{\\text{OPT}}{2}-\\epsilon)$. An immediate application of our results is to maximize submodular functions that are defined stochastically, i.e. the submodular function is defined as an expectation over a family of submodular functions with an unknown distribution. We will show how stochastic gradient methods are naturally well-suited for this setting, leading to a factor $1/2$ approximation when the function is monotone. In particular, it allows us to approximately maximize discrete, monotone submodular optimization problems via projected gradient ascent on a continuous relaxation, directly connecting the discrete and continuous domains. Finally, experiments on real data demonstrate that our projected gradient methods consistently achieve the best utility compared to other continuous baselines while remaining competitive in terms of computational effort.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "Recent studies have shown that proximal gradient (PG) method and accelerated gradient method (APG) with restarting can enjoy a linear convergence under a weaker condition than strong convexity, namely a quadratic growth condition (QGC). However, the faster convergence of restarting APG method relies on the potentially unknown constant  in QGC to appropriately restart APG, which restricts its applicability. We address this issue by developing a novel adaptive gradient converging methods, i.e., leveraging  the magnitude of proximal gradient as a criterion for restart and termination. Our analysis extends to a much more general condition beyond the QGC, namely the H\\\"{o}lderian error bound (HEB) condition.   {\\it The key technique} for our development is a novel synthesis of  {\\it adaptive regularization and a conditional restarting scheme}, which extends previous work focusing on strongly convex problems to a much broader family of problems. Furthermore, we demonstrate that our results have important implication and applications in machine learning: (i) if the objective function is coercive and semi-algebraic, PG's convergence speed is essentially $o(\\frac{1}{t})$, where $t$ is the total number of iterations; (ii) if the objective function consists of an $\\ell_1$, $\\ell_\\infty$, $\\ell_{1,\\infty}$, or huber  norm regularization and a convex smooth piecewise quadratic loss (e.g., square loss, squared hinge loss and huber loss), the proposed algorithm is parameter-free and enjoys a {\\it faster linear convergence} than PG without any other assumptions  (e.g., restricted eigen-value condition).   It is notable that  our linear convergence results for the aforementioned problems  are global instead of local.  To the best of our knowledge, these improved results are first shown in this work.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "Generalized Linear Bandits (GLBs), a natural extension of the stochastic linear bandits, has been popular and successful in recent years.  However, existing GLBs scale poorly with the number of rounds and the number of arms, limiting their utility in practice.  This paper proposes new, scalable solutions to the GLB problem in two respects.  First, unlike existing GLBs, whose per-time-step space and time complexity grow at least linearly with time $t$, we propose a new algorithm that performs online computations to enjoy a constant space and time complexity.  At its heart is a novel Generalized Linear extension of the Online-to-confidence-set Conversion (GLOC method) that takes \\emph{any} online learning algorithm and turns it into a GLB algorithm.  As a special case, we apply GLOC to the online Newton step algorithm, which results in a low-regret GLB algorithm with much lower time and memory complexity than prior work.  Second, for the case where the number $N$ of arms is very large, we propose new algorithms in which each next arm is selected via an inner product search.  Such methods can be implemented via hashing algorithms (i.e., ``hash-amenable'') and result in a time complexity sublinear in $N$.  While a Thompson sampling extension of GLOC is hash-amenable, its regret bound for $d$-dimensional arm sets scales with $d^{3/2}$, whereas GLOC's regret bound scales with $d$.  Towards closing this gap, we propose a new hash-amenable algorithm whose regret bound scales with $d^{5/4}$.  Finally, we propose a fast approximate hash-key computation (inner product) with a better accuracy than the state-of-the-art, which can be of independent interest.  We conclude the paper with preliminary experimental results confirming the merits of our methods.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "The additive model is one of the most popularly used models for high dimensional nonparametric regression analysis. However, its main drawback is that it neglects possible interactions between predictor variables. In this paper, we reexamine the group additive model proposed in the literature, and rigorously define the intrinsic group additive structure for the relationship between the response variable $Y$ and the predictor vector $\\vect{X}$, and further develop an effective structure-penalized kernel method for simultaneous identification of the intrinsic group additive structure and nonparametric function estimation. The method utilizes a novel complexity measure we derive for group additive structures. We show that the proposed method is consistent in identifying the intrinsic group additive structure.  Simulation study and real data applications demonstrate the effectiveness of the proposed method as a general tool for high dimensional nonparametric regression.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "Neural Machine Translation (NMT) has become a popular technology in recent years, and beam search is its de facto decoding method due to the shrunk search space and reduced computational complexity. However, since it only searches for local optima at each time step through one-step forward looking, it usually cannot output the best target sentence. Inspired by the success and methodology of AlphaGo, in this paper we propose using a prediction network to improve beam search, which takes the source sentence $x$, the currently available decoding output $y_1,\\cdots, y_{t-1}$ and a candidate word $w$ at step $t$ as inputs and predicts the long-term value (e.g., BLEU score) of the partial target sentence if it is completed by the NMT model. Following the practice in reinforcement learning, we call this prediction network \\emph{value network}. Specifically, we propose a recurrent structure for the value network, and train its parameters from bilingual data. During the test time, when  choosing a word $w$ for decoding, we consider both its conditional probability given by the NMT model and its long-term value predicted by the value network. Experiments show that such an approach can significantly improve the translation accuracy on several translation tasks.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "This work constructs a hypothesis test for detecting whether an data-generating function $h: \\real^p \\rightarrow \\real$ belongs to a specific reproducing kernel Hilbert space $\\mathcal{H}_0$, where the structure of $\\mathcal{H}_0$ is only partially known. Utilizing the theory of reproducing kernels, we reduce this hypothesis to a simple one-sided score test for a scalar parameter, develop a testing procedure that is robust against the mis-specification of kernel functions, and also propose an ensemble-based estimator for the null model to guarantee test performance in small samples. To demonstrate the utility of the proposed method, we apply our test to the problem of detecting nonlinear interaction between groups of continuous features. We evaluate the finite-sample performance of our test  under different data-generating functions and estimation strategies for the null model. Our results revealed interesting connection between notions in machine learning (model underfit/overfit) and those in statistical inference (i.e. Type I error/power of hypothesis test), and also highlighted unexpected consequences of common model estimating strategies (e.g. estimating kernel hyperparameters using maximum likelihood estimation) on model inference.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "Graph clustering is a fundamental task in many data-mining and machine-learning pipelines. In particular, identifying a good hierarchical structure is at the same time a fundamental and challenging problem for several applications. The amount of data to analyze is increasing at an astonishing rate each day. Hence there is a need for new solutions to efficiently compute effective hierarchical clusterings on such huge data.  The main focus of this paper is on minimum spanning tree (MST) based clusterings. In particular, we propose affinity, a novel hierarchical clustering based on Boruvka's MST algorithm. We prove certain theoretical guarantees for affinity (as well as some other classic algorithms) and show that in practice it is superior to several other state-of-the-art clustering algorithms.   Furthermore, we present two MapReduce implementations for affinity. The first one works for the case where the input graph is dense and takes constant rounds. It is based on a Massively Parallel MST algorithm for dense graphs that improves upon the state-of-the-art algorithm of Lattanzi et al. (SPAA 2011). Our second algorithm has no assumption on the density of the input graph and finds the affinity clustering in $O(\\log n)$ rounds using Distributed Hash Tables (DHTs). We show experimentally that our algorithms are scalable for huge data sets, e.g., for graphs with trillions of edges.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "Nowozin \\textit{et al} showed last year how to extend the GAN \\textit{principle} to all $f$-divergences. The approach is elegant but falls short of a full description of the supervised game, and says little about the key player, the generator: for example, what does the generator actually converge to if solving the GAN game means convergence in some space of parameters? How does that provide hints on the generator's design and compare to the flourishing but almost exclusively experimental literature on the subject? In this paper, we unveil a broad class of distributions for which such convergence happens --- namely, deformed exponential families, a wide superset of exponential families ---. We show that current deep architectures are able to factorize a very large number of such densities using an especially compact design, hence displaying the power of deep architectures and their concinnity in the $f$-GAN game. This result holds given a sufficient condition on \\textit{activation functions} ---  which turns out to be satisfied by popular choices. The key to our results is a variational generalization of an old theorem that relates the KL divergence between regular exponential families and divergences between their natural parameters. We complete this picture with additional results and experimental insights on how these results may be used to ground further improvements of GAN architectures, via (i) a principled design of the activation functions in the generator and (ii) an explicit integration of proper composite losses' link function in the discriminator.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "Directed latent variable models that formulate the joint distribution as $p(x,z) = p(z) p(x \\mid z)$ have the advantage of fast and exact sampling. However, these models have the weakness of needing to specify $p(z)$, often with a simple fixed prior that limits the expressiveness of the model.  Undirected latent variable models discard the requirement that $p(z)$ be specified with a prior, yet sampling from them generally requires an iterative procedure such as blocked Gibbs-sampling that may require many steps to draw samples from the joint distribution $p(x, z)$.  We propose a novel approach to learning the joint distribution between the data and a latent code which uses an adversarially learned iterative procedure to gradually refine the joint distribution, $p(x, z)$, to better match with the data distribution on each step.  GibbsNet is the best of both worlds both in theory and in practice.  Achieving the speed and simplicity of a directed latent variable model, it is guaranteed (assuming the adversarial game reaches the virtual training criteria global minimum) to produce samples from $p(x, z)$ with only a few sampling iterations.  Achieving the expressiveness and flexibility of an undirected latent variable model, GibbsNet does away with the need for an explicit $p(z)$ and has the ability to do attribute prediction, class-conditional generation, and joint image-attribute modeling in a single model which is not trained for any of these specific tasks.  We show empirically that GibbsNet is able to learn a more complex $p(z)$ and show that this leads to improved inpainting and iterative refinement of $p(x, z)$ for dozens of steps and stable generation without collapse for thousands of steps, despite being trained on only a few steps.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "We present theoretical guarantees for an alternating minimization algorithm for the dictionary learning/sparse coding problem. The dictionary learning problem is to factorize vector samples $y^{1},y^{2},\\ldots, y^{n}$ into an appropriate basis (dictionary) $A^*$ and sparse vectors $x^{1*},\\ldots,x^{n*}$. Our algorithm is a simple alternating minimization procedure that switches between $\\ell_1$ minimization and gradient descent in alternate steps. Dictionary learning and specifically alternating minimization algorithms for dictionary learning are well studied both theoretically and empirically. However, in contrast to previous theoretical analyses for this problem, we replace a condition on the operator norm (that is, the largest magnitude singular value) of the true underlying dictionary $A^*$ with a condition on the matrix infinity norm (that is, the largest magnitude term). This not only allows us to get convergence rates for the error of the estimated dictionary measured in the matrix infinity norm, but also ensures that a random initialization will provably converge to the global optimum. Our guarantees are under a reasonable generative model that allows for dictionaries with growing operator norms, and can handle an arbitrary level of overcompleteness, while having sparsity that is information theoretically optimal. We also establish upper bounds on the sample complexity of our algorithm.\n",
            "2\n",
            "The $k$-means clustering algorithm is a ubiquitous tool in data mining and machine learning that shows promising performance. However, its high computational cost has hindered its applications in broad domains. Researchers have successfully addressed these obstacles with dimensionality reduction methods. Recently, [1] develop a state-of-the-art random projection (RP) method for faster $k$-means clustering. Their method delivers many improvements over other dimensionality reduction methods. For example, compared to the advanced singular value decomposition based feature extraction approach,  [1] reduce the running time by a factor of $\\min \\{n,d\\}\\epsilon^2 log(d)/k$ for data matrix $X \\in \\mathbb{R}^{n\\times d} $ with $n$ data points and $d$ features, while losing only a factor of one in approximation accuracy. Unfortunately, they still require $\\mathcal{O}(\\frac{ndk}{\\epsilon^2log(d)})$ for matrix multiplication and this cost will be prohibitive for large values of $n$ and $d$. To break this bottleneck, we carefully build a sparse embedded $k$-means clustering algorithm which requires $\\mathcal{O}(nnz(X))$ ($nnz(X)$ denotes the number of non-zeros in $X$) for fast matrix multiplication. Moreover, our proposed algorithm improves on [1]'s results for approximation accuracy by a factor of one. Our empirical studies corroborate our theoretical findings, and demonstrate that our approach is able to significantly accelerate $k$-means clustering, while achieving satisfactory clustering performance.\n",
            "2\n",
            "Optimization with noisy gradients has become ubiquitous in statistics and machine learning. Reparameterization gradients, or gradient estimates computed via the ``reparameterization trick,'' represent a class of noisy gradients often used in Monte Carlo variational inference (MCVI). However, when these gradient estimators are too noisy, the optimization procedure can be slow or fail to converge. One way to reduce noise is to generate more samples for the gradient estimate, but this can be computationally expensive. Instead, we view the noisy gradient as a random variable, and form an inexpensive approximation of the generating procedure for the gradient sample. This approximation has high correlation with the noisy gradient by construction, making it a useful control variate for variance reduction. We demonstrate our approach on a non-conjugate hierarchical model and a Bayesian neural net where our method attained orders of magnitude (20-2{,}000$\\times$) reduction in gradient variance resulting in faster and more stable optimization.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "We present a new affine-invariant optimization algorithm called Online Lazy Newton. The regret of Online Lazy Newton is independent of conditioning: the algorithm's performance depends on the best possible preconditioning of the problem in retrospect and on its \\emph{intrinsic} dimensionality. As an application, we show how Online Lazy Newton can be used to achieve an optimal regret of order $\\sqrt{rT}$ for the low-rank experts problem, improving by a $\\sqrt{r}$ factor over the previously best known bound and resolving an open problem posed by Hazan et al (2016).\n",
            "2\n",
            "This paper proposes the novel Pose Guided Person Generation Network (PG$^2$) that allows to synthesize person images in arbitrary poses, based on an image of that person and a novel pose. Our generation framework PG$^2$ utilizes the pose information explicitly and consists of two key stages: pose integration and image refinement. In the first stage the condition image and the target pose are fed into a U-Net-like network to generate an initial but coarse image of the person with the target pose. The second stage then refines the initial and blurry result by training a U-Net-like generator in an adversarial way. Extensive experimental results on both 128$\\times$64 re-identification images and 256$\\times$256 fashion photos show that our model generates high-quality person images with convincing details.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "Variational inference (VI) is widely used as an efficient alternative to Markov chain Monte Carlo. It posits a family of approximating distributions $q$ and finds the closest member to the exact posterior $p$. Closeness is usually measured via a divergence $D(q || p)$ from $q$ to $p$. While successful, this approach also has problems. Notably, it typically leads to underestimation of the posterior variance. In this paper we propose CHIVI, a black-box variational inference algorithm that minimizes $D_{\\chi}(p || q)$, the $\\chi$-divergence from $p$ to $q$. CHIVI minimizes an upper bound of the model evidence, which we term the $\\chi$ upper bound (CUBO). Minimizing the CUBO leads to improved posterior uncertainty, and it can also be used with the classical VI lower bound (ELBO) to provide a sandwich estimate of the model evidence. We study CHIVI on three models: probit regression, Gaussian process classification, and a Cox process model of basketball plays. When compared to expectation propagation and classical VI, CHIVI produces better error rates and more accurate estimates of posterior variance.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "We present an algorithm based on posterior sampling (aka Thompson sampling) that achieves near-optimal worst-case regret bounds when the underlying Markov Decision Process (MDP) is communicating with a finite, though unknown, diameter. Our main result is a high probability regret upper bound of $\\tilde{O}(D\\sqrt{SAT})$ for any communicating MDP with $S$ states, $A$ actions and diameter $D$, when $T\\ge S^5A$. Here, regret compares the total reward achieved by the algorithm to the total expected reward of an optimal infinite-horizon undiscounted average reward policy, in time horizon $T$. This result improves over the best previously known upper bound of $\\tilde{O}(DS\\sqrt{AT})$ achieved by any algorithm in this setting, and matches the dependence on $S$ in the established lower bound of $\\Omega(\\sqrt{DSAT})$ for this problem. Our techniques involve proving some novel results about the anti-concentration of Dirichlet distribution, which may be of independent interest.\n",
            "2\n",
            "Online kernel learning (OKL) is a flexible framework to approach prediction problems, since the large approximation space provided by reproducing kernel Hilbert spaces can contain an accurate function for the problem. Nonetheless, optimizing over this space is computationally expensive. Not only first order methods accumulate $\\O(\\sqrt{T})$ more loss than the optimal function, but the curse of kernelization results in a $\\O(t)$ per step complexity. Second-order methods get closer to the optimum much faster, suffering only $\\O(\\log(T))$ regret, but second-order updates are even more expensive, with a $\\O(t^2)$ per-step cost. Existing approximate OKL methods try to reduce this complexity either by limiting the Support Vectors (SV) introduced in the predictor, or by avoiding the kernelization process altogether using embedding. Nonetheless, as long as the size of the approximation space or the number of SV does not grow over time, an adversary can always exploit the approximation process. In this paper, we propose PROS-N-KONS, a method that combines Nystrom sketching to project the input point in a small, accurate embedded space, and performs efficient second-order updates in this space. The embedded space is continuously updated to guarantee that the embedding remains accurate, and we show that the per-step cost only grows with the effective dimension of the problem and not with $T$. Moreover, the second-order updated allows us to achieve the logarithmic regret. We empirically compare our algorithm on recent large-scales benchmarks and show it performs favorably.\n",
            "2\n",
            "This paper deals with finding an $n$-dimensional solution $\\bm{x}$ to a system of quadratic equations $y_i=|\\langle\\bm{a}_i,\\bm{x}\\rangle|^2$, $1\\le i \\le m$, which in general is known to be NP-hard. We put forth a novel procedure, that starts with a \\emph{weighted maximal correlation initialization} obtainable with a few power iterations, followed by successive refinements based on \\emph{iteratively reweighted gradient-type iterations}. The novel techniques distinguish themselves from prior works by the inclusion of a fresh (re)weighting regularization. For certain random measurement models, the proposed procedure returns the true solution $\\bm{x}$ with high probability in time proportional to reading the data $\\{(\\bm{a}_i;y_i)\\}_{1\\le i \\le m}$, provided that the number $m$ of equations is some constant $c>0$ times the number $n$ of unknowns, that is, $m\\ge cn$. Empirically, the upshots of this contribution are: i) perfect signal recovery in the high-dimensional regime given only an \\emph{information-theoretic limit number} of equations; and, ii) (near-)optimal statistical accuracy in the presence of additive noise. Extensive numerical tests using both synthetic data and real images corroborate its improved signal recovery performance and computational efficiency relative to state-of-the-art approaches.\n",
            "2\n",
            "We study online reinforcement learning in average-reward stochastic games (SGs). An SG models a two-player zero-sum game in a Markov environment, where state transitions and one-step payoffs are determined simultaneously by a learner and an adversary. We propose the \\textsc{UCSG} algorithm that achieves a sublinear regret compared to the game value when competing with an arbitrary opponent. This result improves previous ones under the same setting. The regret bound has a dependency on the \\textit{diameter}, which is an intrinsic value related to the mixing property of SGs. Slightly extended, \\textsc{UCSG} finds an $\\varepsilon$-maximin stationary policy with a sample complexity of $\\tilde{\\mathcal{O}}\\left(\\text{poly}(1/\\varepsilon)\\right)$, where $\\varepsilon$ is the error parameter. To the best of our knowledge, this extended result is the first in the average-reward setting. In the analysis, we develop Markov chain's perturbation bounds for mean first passage times and techniques to deal with non-stationary opponents, which may be of interest in their own right.\n",
            "2\n",
            "The  independence clustering problem is considered in the following formulation: given a set $S$ of random variables,  it is required to find the finest partitioning $\\{U_1,\\dots,U_k\\}$ of  $S$ into clusters  such that the clusters $U_1,\\dots,U_k$ are mutually independent. Since mutual independence is the target, pairwise similarity measurements are of no use, and thus traditional clustering algorithms are inapplicable.   The distribution of the random variables in $S$ is, in general, unknown, but a sample  is available.  Thus, the problem is cast in terms of time series.  Two forms of sampling are considered: i.i.d.\\ and stationary  time series, with the main emphasis being on the latter, more general, case. A consistent, computationally tractable algorithm for each of the settings is proposed, and a number of fascinating open directions for further research are outlined.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "Most recently proposed methods for Neural Program induction work under the assumption of having a large set of input/output (I/O) examples for learning any given input-output mapping. This paper aims to address the problem of data and computation efficiency of program induction by leveraging information from related tasks. Specifically, we propose two novel approaches for cross-task knowledge transfer to improve program induction in limited-data scenarios. In our first proposal, portfolio adaptation, a set of induction models is pretrained on a set of related tasks, and the best model is adapted towards the new task using transfer learning. In our second approach, meta program induction, a $k$-shot learning approach is used to make a model generalize to new tasks without additional training. To test the efficacy of our methods, we constructed a new benchmark of programs written in the Karel programming language. Using an extensive experimental evaluation on the Karel benchmark, we demonstrate that our proposals dramatically outperform the baseline induction method that does not use knowledge transfer. We also analyze the relative performance of the two approaches and study conditions in which they perform best. In particular, meta induction outperforms all existing approaches under extreme data sparsity (when a very small number of examples are available), i.e., fewer than ten. As the number of available I/O examples increase (i.e. a thousand or more), portfolio adapted program induction becomes the best approach. For intermediate data sizes, we demonstrate that the combined method of adapted meta program induction has the strongest performance.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "We present new practical local differentially private heavy hitters algorithms achieving optimal or near-optimal worst-case error -- TreeHist and Bitstogram. In both algorithms, server running time is $\\tilde O(n)$ and user running time is $\\tilde O(1)$, hence improving on the prior state-of-the-art result of Bassily and Smith [STOC 2015] requiring $\\tilde O(n^{5/2})$ server time and $\\tilde O(n^{3/2})$ user time. With a typically large number of participants in local algorithms ($n$ in the millions), this reduction in time complexity, in particular at the user side, is crucial for the use of such algorithms in practice. We implemented Algorithm TreeHist to verify our theoretical analysis and compared its performance with the performance of Google's RAPPOR code.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "We consider the problem of estimating the values of a function over $n$ nodes of a $d$-dimensional grid graph (having equal side lengths $n^{1/d}$) from noisy observations. The function is assumed to be smooth, but is allowed to exhibit different amounts of smoothness at different regions in the grid. Such heterogeneity eludes classical measures of smoothness from nonparametric statistics, such as Holder smoothness. Meanwhile, total variation (TV) smoothness classes allow for heterogeneity, but are restrictive in another sense: only constant functions count as perfectly smooth (achieve zero TV). To move past this, we define two new higher-order TV classes, based on two ways of compiling the discrete derivatives of a parameter across the nodes. We relate these two new classes to Holder classes, and derive lower bounds on their minimax errors. We also analyze two naturally associated trend filtering methods; when $d=2$, each is seen to be rate optimal over the appropriate class.\n",
            "2\n",
            "Conditional probabilities are a core concept in machine learning. For example, optimal prediction of a label $Y$ given an input $X$ corresponds to maximizing the conditional probability of $Y$ given $X$. A common approach to inference tasks is learning a model of conditional probabilities. However, these models are often based on strong assumptions (e.g., log-linear models), and hence their estimate of conditional probabilities is not robust and is highly dependent on the validity of their assumptions.  Here we propose a framework for reasoning about conditional probabilities without assuming anything about the underlying distributions, except knowledge of their second order marginals, which can be estimated from data. We show how this setting leads to guaranteed bounds on conditional probabilities, which can be calculated efficiently in a variety of settings, including structured-prediction. Finally, we apply them to semi-supervised deep learning, obtaining results competitive with variational autoencoders.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "We provide new results for noise-tolerant and sample-efficient learning algorithms under $s$-concave distributions. The new class of $s$-concave distributions is a broad and natural generalization of log-concavity, and includes many important additional distributions, e.g., the Pareto distribution and $t$ distribution. This class has been studied in the context of efficient sampling, integration, and optimization, but much remains unknown about the geometry of this class of distributions and their applications in the context of learning. The challenge is that unlike the commonly used distributions in learning (uniform or more generally log-concave distributions), this broader class is not closed under the marginalization operator and many such distributions are fat-tailed. In this work, we introduce new convex geometry tools to study the properties of $s$-concave distributions and use these properties to provide bounds on quantities of interest to learning including the probability of disagreement between two halfspaces, disagreement outside a band, and the disagreement coefficient. We use these results to significantly generalize prior results for margin-based active learning, disagreement-based active learning, and passive learning of intersections of halfspaces. Our analysis of geometric properties of $s$-concave distributions might be of independent interest to optimization more broadly.\n",
            "2\n",
            "We introduce and analyze a new technique for model reduction for deep neural networks. While large networks are theoretically capable of learning arbitrarily complex models, overfitting and model redundancy negatively affects the prediction accuracy and model variance.  Our Net-Trim algorithm prunes (sparsifies) a trained network layer-wise, removing connections at each layer by solving a convex optimization program.  This program seeks a sparse set of weights at each layer that keeps the layer inputs and outputs consistent with the originally trained model.  The algorithms and associated analysis are applicable to neural networks operating with the rectified linear unit (ReLU) as the nonlinear activation. We present both parallel and cascade versions of the algorithm.  While the latter can achieve slightly simpler models with the same generalization performance, the former can be computed in a distributed manner.  In both cases, Net-Trim significantly reduces the number of connections in the network, while also providing enough regularization to slightly reduce the generalization error. We also provide a mathematical analysis of the consistency between the initial network and the retrained model.  To analyze the model sample complexity, we derive the general sufficient conditions for the recovery of a sparse transform matrix. For a single layer taking independent Gaussian random vectors of length $N$ as inputs,  we show that if the network response can be described using a maximum number of $s$ non-zero weights per node, these weights can be learned from $\\mathcal{O}(s\\log N)$ samples.\n",
            "2\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "2\n",
            "\n",
            "3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-6543334a57ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpapers_url\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mhtmlContent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0msoup\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtmlContent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mabstracts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "1j9Ou1cHPmPL",
        "outputId": "d32403ea-02ec-49e3-878c-9adeba0911f4"
      },
      "source": [
        "print(count))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-89-e9e59465cef9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print(count))\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}